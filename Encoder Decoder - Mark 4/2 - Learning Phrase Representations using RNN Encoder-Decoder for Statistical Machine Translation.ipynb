{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0b835a",
   "metadata": {
    "papermill": {
     "duration": 0.025409,
     "end_time": "2021-10-18T19:09:39.309458",
     "exception": false,
     "start_time": "2021-10-18T19:09:39.284049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a271d66",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-18T19:09:39.364020Z",
     "iopub.status.busy": "2021-10-18T19:09:39.362434Z",
     "iopub.status.idle": "2021-10-18T19:09:49.110036Z",
     "shell.execute_reply": "2021-10-18T19:09:49.109366Z",
     "shell.execute_reply.started": "2021-10-18T19:01:37.064642Z"
    },
    "papermill": {
     "duration": 9.775595,
     "end_time": "2021-10-18T19:09:49.110192",
     "exception": false,
     "start_time": "2021-10-18T19:09:39.334597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b010be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:09:49.163139Z",
     "iopub.status.busy": "2021-10-18T19:09:49.162477Z",
     "iopub.status.idle": "2021-10-18T19:09:49.167001Z",
     "shell.execute_reply": "2021-10-18T19:09:49.166569Z",
     "shell.execute_reply.started": "2021-10-18T19:01:47.282519Z"
    },
    "papermill": {
     "duration": 0.032522,
     "end_time": "2021-10-18T19:09:49.167110",
     "exception": false,
     "start_time": "2021-10-18T19:09:49.134588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392ed736",
   "metadata": {
    "papermill": {
     "duration": 0.024866,
     "end_time": "2021-10-18T19:09:49.215767",
     "exception": false,
     "start_time": "2021-10-18T19:09:49.190901",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18de6637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:09:49.268255Z",
     "iopub.status.busy": "2021-10-18T19:09:49.267443Z",
     "iopub.status.idle": "2021-10-18T19:10:06.580560Z",
     "shell.execute_reply": "2021-10-18T19:10:06.580103Z",
     "shell.execute_reply.started": "2021-10-18T19:01:47.291255Z"
    },
    "papermill": {
     "duration": 17.340712,
     "end_time": "2021-10-18T19:10:06.580686",
     "exception": false,
     "start_time": "2021-10-18T19:09:49.239974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (58.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting de-core-news-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.1.0/de_core_news_sm-3.1.0-py3-none-any.whl (18.8 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from de-core-news-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (58.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.1)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli \n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2531f5ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:06.642161Z",
     "iopub.status.busy": "2021-10-18T19:10:06.641337Z",
     "iopub.status.idle": "2021-10-18T19:10:09.230644Z",
     "shell.execute_reply": "2021-10-18T19:10:09.230138Z",
     "shell.execute_reply.started": "2021-10-18T19:02:04.948821Z"
    },
    "papermill": {
     "duration": 2.622166,
     "end_time": "2021-10-18T19:10:09.230779",
     "exception": false,
     "start_time": "2021-10-18T19:10:06.608613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating tokenizers\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccdb7d9",
   "metadata": {
    "papermill": {
     "duration": 0.027836,
     "end_time": "2021-10-18T19:10:09.286784",
     "exception": false,
     "start_time": "2021-10-18T19:10:09.258948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **Previously we reversed the source (German) sentence, however in the paper we are implementing they don't do this, so neither will we.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c3f086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:09.347678Z",
     "iopub.status.busy": "2021-10-18T19:10:09.346833Z",
     "iopub.status.idle": "2021-10-18T19:10:09.348845Z",
     "shell.execute_reply": "2021-10-18T19:10:09.349252Z",
     "shell.execute_reply.started": "2021-10-18T19:02:10.645854Z"
    },
    "papermill": {
     "duration": 0.035137,
     "end_time": "2021-10-18T19:10:09.349372",
     "exception": false,
     "start_time": "2021-10-18T19:10:09.314235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens)\n",
    "    \n",
    "    :param text: the german sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \n",
    "    :param text: the english sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "105822d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:09.409449Z",
     "iopub.status.busy": "2021-10-18T19:10:09.408607Z",
     "iopub.status.idle": "2021-10-18T19:10:09.411178Z",
     "shell.execute_reply": "2021-10-18T19:10:09.410622Z",
     "shell.execute_reply.started": "2021-10-18T19:02:12.684228Z"
    },
    "papermill": {
     "duration": 0.03419,
     "end_time": "2021-10-18T19:10:09.411277",
     "exception": false,
     "start_time": "2021-10-18T19:10:09.377087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source is in German and Target is in English\n",
    "\n",
    "SRC = Field(tokenize = tokenize_de,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6f4a594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:09.470309Z",
     "iopub.status.busy": "2021-10-18T19:10:09.469490Z",
     "iopub.status.idle": "2021-10-18T19:10:19.628900Z",
     "shell.execute_reply": "2021-10-18T19:10:19.628386Z",
     "shell.execute_reply.started": "2021-10-18T19:02:14.495595Z"
    },
    "papermill": {
     "duration": 10.190529,
     "end_time": "2021-10-18T19:10:19.629037",
     "exception": false,
     "start_time": "2021-10-18T19:10:09.438508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 651kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 175kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 166kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and load the train, valid and test data\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'),\n",
    "    fields = (SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c962d7d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:19.706116Z",
     "iopub.status.busy": "2021-10-18T19:10:19.705447Z",
     "iopub.status.idle": "2021-10-18T19:10:19.708401Z",
     "shell.execute_reply": "2021-10-18T19:10:19.708842Z",
     "shell.execute_reply.started": "2021-10-18T19:02:22.874549Z"
    },
    "papermill": {
     "duration": 0.04351,
     "end_time": "2021-10-18T19:10:19.708964",
     "exception": false,
     "start_time": "2021-10-18T19:10:19.665454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n",
      "{'src': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"
     ]
    }
   ],
   "source": [
    "# Verifying\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75772999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:19.828226Z",
     "iopub.status.busy": "2021-10-18T19:10:19.817939Z",
     "iopub.status.idle": "2021-10-18T19:10:20.061658Z",
     "shell.execute_reply": "2021-10-18T19:10:20.061176Z",
     "shell.execute_reply.started": "2021-10-18T19:02:24.434606Z"
    },
    "papermill": {
     "duration": 0.317281,
     "end_time": "2021-10-18T19:10:20.061788",
     "exception": false,
     "start_time": "2021-10-18T19:10:19.744507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# building vocabulary\n",
    "# min_freq => min threshold to include the word in the vocab\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c77584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:20.137856Z",
     "iopub.status.busy": "2021-10-18T19:10:20.137190Z",
     "iopub.status.idle": "2021-10-18T19:10:20.140019Z",
     "shell.execute_reply": "2021-10-18T19:10:20.140459Z",
     "shell.execute_reply.started": "2021-10-18T19:02:26.513647Z"
    },
    "papermill": {
     "duration": 0.043175,
     "end_time": "2021-10-18T19:10:20.140603",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.097428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7853\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "# Unique Tokens\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b7158a",
   "metadata": {
    "papermill": {
     "duration": 0.035915,
     "end_time": "2021-10-18T19:10:20.212779",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.176864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f449388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:20.291602Z",
     "iopub.status.busy": "2021-10-18T19:10:20.290946Z",
     "iopub.status.idle": "2021-10-18T19:10:20.293192Z",
     "shell.execute_reply": "2021-10-18T19:10:20.293621Z",
     "shell.execute_reply.started": "2021-10-18T19:02:29.234537Z"
    },
    "papermill": {
     "duration": 0.04432,
     "end_time": "2021-10-18T19:10:20.293740",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.249420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914dc444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:20.371806Z",
     "iopub.status.busy": "2021-10-18T19:10:20.370332Z",
     "iopub.status.idle": "2021-10-18T19:10:20.374096Z",
     "shell.execute_reply": "2021-10-18T19:10:20.373678Z",
     "shell.execute_reply.started": "2021-10-18T19:02:30.656131Z"
    },
    "papermill": {
     "duration": 0.043109,
     "end_time": "2021-10-18T19:10:20.374201",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.331092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847aaf87",
   "metadata": {
    "papermill": {
     "duration": 0.038212,
     "end_time": "2021-10-18T19:10:20.448975",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.410763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093984b",
   "metadata": {
    "papermill": {
     "duration": 0.038306,
     "end_time": "2021-10-18T19:10:20.525887",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.487581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebffa6cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:20.606593Z",
     "iopub.status.busy": "2021-10-18T19:10:20.605711Z",
     "iopub.status.idle": "2021-10-18T19:10:20.607530Z",
     "shell.execute_reply": "2021-10-18T19:10:20.607983Z",
     "shell.execute_reply.started": "2021-10-18T19:02:34.654963Z"
    },
    "papermill": {
     "duration": 0.045685,
     "end_time": "2021-10-18T19:10:20.608107",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.562422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        \"\"\"\n",
    "        :param input_dim: It is the size/dimensionality of the one-hot vectors that will be input to the encoder. \n",
    "                        This is equal to the input (source) vocabulary size.\n",
    "        :param emb_dim: It is the dimensionality of the embedding layer. \n",
    "                        This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "        :param hid_dim: It is the dimensionality of the hidden and cell states\n",
    "        :param dropout: It is the amount of dropout to use. \n",
    "                        This is a regularization parameter to prevent overfitting.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) # no dropout as only one layer\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        # src.shape => (src_len, batch_size)\n",
    "\n",
    "        # example, src will be like:\n",
    "\n",
    "            # | I ,     Good,       How,    ... |\n",
    "            # | have,   morning,    are,    ... |\n",
    "            # | a,      <eos>,      you,    ... |\n",
    "            # | dog,    <pad>,      <eos>,  ... |\n",
    "            # | <eos>,  <pad>,      <pad>,  ... |\n",
    "\n",
    "            # In this number of rows = src_len or max_len\n",
    "            # and number of columns = batch_size\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded.shape => (src_len, batch_size, emb_dim)\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded) # no cell state!\n",
    "        \n",
    "        # outputs.shape => (src_len, batch_size, hid_dim * n_directions)\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        \n",
    "        # outputs are always from top hidden layer\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21de299",
   "metadata": {
    "papermill": {
     "duration": 0.035721,
     "end_time": "2021-10-18T19:10:20.726174",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.690453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decoder\n",
    "\n",
    "* Instead of the GRU in the decoder taking just the embedded target token, $d(y_t)$ and the previous hidden state $s_{t-1}$ as inputs, it also takes the context vector $z$.\n",
    "* Before, we predicted the next token, $\\hat{y}_{t+1}$, with the linear layer, $f$, only using the top-layer decoder hidden state at that time-step, $s_t$, as $\\hat{y}_{t+1}=f(s_t^L)$. Now, we also pass the embedding of current token, $d(y_t)$ and the context vector, $z$ to the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8f14ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:20.809800Z",
     "iopub.status.busy": "2021-10-18T19:10:20.807175Z",
     "iopub.status.idle": "2021-10-18T19:10:20.812267Z",
     "shell.execute_reply": "2021-10-18T19:10:20.811830Z",
     "shell.execute_reply.started": "2021-10-18T19:05:17.095627Z"
    },
    "papermill": {
     "duration": 0.049652,
     "end_time": "2021-10-18T19:10:20.812383",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.762731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        \"\"\"\n",
    "        :param output_dim: It is the size/dimensionality of the one-hot vectors that will be input to the decoder. \n",
    "                        This is equal to the output (target) vocabulary size.\n",
    "                        It also used to output the word in the Linear layer.\n",
    "        :param emb_dim: It is the dimensionality of the embedding layer. \n",
    "                        This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "        :param hid_dim: It is the dimensionality of the hidden and cell states\n",
    "        :param dropout: It is the amount of dropout to use. \n",
    "                        This is a regularization parameter to prevent overfitting.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(emb_dim + hid_dim * 2, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, context):\n",
    "        \n",
    "        # input.shape => (batch_size)\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        # context.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        \n",
    "        # n_layers and n_diections in the decoder will both always be 1, therefore:\n",
    "        # hidden.shape => (1, batch_size, hid_dim)\n",
    "        # context.shape => (1, batch_size, hid_dim)\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        # input.shape => (1, batch_size)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded.shape => (1, batch_size, emb_dim)\n",
    "        \n",
    "        emb_con = torch.cat((embedded, context), dim=2) # i.e concatenate along 2th dimension\n",
    "        # => both of their 2th dimension will be concatenated\n",
    "        # emb_con.shape => (1, batch_size, emb_dim + hid_dim)\n",
    "        \n",
    "        output, hidden = self.rnn(emb_con, hidden)\n",
    "        \n",
    "        # output.shape => (seq_len, batch_size, hid_dim * n_directions)\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        \n",
    "        # seq_len, n_layers and n_directions will always be 1 in the decoder, therefore:\n",
    "        # output.shape => (1, batch_size, hid_dim)\n",
    "        # hidden.shape => (1, batch_size, hid_dim)\n",
    "        \n",
    "        # We pass the embedding, the hidden produced and the original encoder context to the Linear layer\n",
    "        # for translated word embedding prediction\n",
    "        # Note: we are squeezing the 0th dimension of embedded, hidden and context\n",
    "        output = torch.cat((embedded.squeeze(0), hidden.squeeze(0), context.squeeze(0)), dim = 1)\n",
    "        # output.shape => (batch_size, emb_dim + hidden * 2)\n",
    "        \n",
    "        prediction = self.fc_out(output)\n",
    "        # prediction.shape => (batch_size, output_dim)\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb9390",
   "metadata": {
    "papermill": {
     "duration": 0.040764,
     "end_time": "2021-10-18T19:10:20.890423",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.849659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebc11f68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:20.974899Z",
     "iopub.status.busy": "2021-10-18T19:10:20.973880Z",
     "iopub.status.idle": "2021-10-18T19:10:20.984678Z",
     "shell.execute_reply": "2021-10-18T19:10:20.985126Z",
     "shell.execute_reply.started": "2021-10-18T19:05:50.236089Z"
    },
    "papermill": {
     "duration": 0.054316,
     "end_time": "2021-10-18T19:10:20.985293",
     "exception": false,
     "start_time": "2021-10-18T19:10:20.930977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "        :param src: the source sentence sequence\n",
    "                    src.shape => (src_len, batch_size)\n",
    "        :param trg: the target sentence sequence\n",
    "                    trg.shape => (trg_len, batch_size)\n",
    "        :param teacher_forcing_ratio: the ratio, used for training. It tells \n",
    "                    by how much probability, we should use the decoded token or\n",
    "                    the original token for training\n",
    "                    e.g. if teacher_forcing_ratio is 0.75, \n",
    "                    we use ground-truth inputs 75% of the time.\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # last hidden state of the encoder is the context\n",
    "        context = self.encoder(src)\n",
    "        \n",
    "        # context also used as the initial hidden state of the decoder\n",
    "        hidden = context\n",
    "        \n",
    "        # first input to the decoder is the <sos> token s\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            # insert input token embedding, previous hidden state and the context state\n",
    "            # receive output tensor (predictions) and the new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            \n",
    "            # place the predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # get the highest predicted token from out predictions\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # else, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d1b44e",
   "metadata": {
    "papermill": {
     "duration": 0.040449,
     "end_time": "2021-10-18T19:10:21.069281",
     "exception": false,
     "start_time": "2021-10-18T19:10:21.028832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf67bb",
   "metadata": {
    "papermill": {
     "duration": 0.037044,
     "end_time": "2021-10-18T19:10:21.143745",
     "exception": false,
     "start_time": "2021-10-18T19:10:21.106701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Init the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975c26df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:21.225851Z",
     "iopub.status.busy": "2021-10-18T19:10:21.225304Z",
     "iopub.status.idle": "2021-10-18T19:10:29.866943Z",
     "shell.execute_reply": "2021-10-18T19:10:29.866398Z",
     "shell.execute_reply.started": "2021-10-18T19:05:51.504554Z"
    },
    "papermill": {
     "duration": 8.686249,
     "end_time": "2021-10-18T19:10:29.867080",
     "exception": false,
     "start_time": "2021-10-18T19:10:21.180831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b7778c",
   "metadata": {
    "papermill": {
     "duration": 0.037529,
     "end_time": "2021-10-18T19:10:29.942677",
     "exception": false,
     "start_time": "2021-10-18T19:10:29.905148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing weights of the model.\n",
    "\n",
    "Next, we initialize our parameters. The paper states the parameters are initialized from a normal distribution with a mean of 0 and a standard deviation of 0.01, i.e. $\\mathcal{N}(0, 0.01)$.\n",
    "\n",
    "It also states we should initialize the recurrent parameters to a special initialization, however to keep things simple we'll also initialize them to $\\mathcal{N}(0, 0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add06785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.023085Z",
     "iopub.status.busy": "2021-10-18T19:10:30.022215Z",
     "iopub.status.idle": "2021-10-18T19:10:30.030662Z",
     "shell.execute_reply": "2021-10-18T19:10:30.031402Z",
     "shell.execute_reply.started": "2021-10-18T19:05:59.756778Z"
    },
    "papermill": {
     "duration": 0.05126,
     "end_time": "2021-10-18T19:10:30.031587",
     "exception": false,
     "start_time": "2021-10-18T19:10:29.980327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(768, 512)\n",
       "    (fc_out): Linear(in_features=1280, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "        initializes the weights of the model.\n",
    "    \"\"\"\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9858ffb",
   "metadata": {
    "papermill": {
     "duration": 0.036302,
     "end_time": "2021-10-18T19:10:30.105160",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.068858",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Even though we only have a single layer RNN for our encoder and decoder we actually have more parameters than the last model. This is due to the increased size of the inputs to the GRU and the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6de3881d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.183974Z",
     "iopub.status.busy": "2021-10-18T19:10:30.183203Z",
     "iopub.status.idle": "2021-10-18T19:10:30.186575Z",
     "shell.execute_reply": "2021-10-18T19:10:30.186957Z",
     "shell.execute_reply.started": "2021-10-18T19:05:59.771600Z"
    },
    "papermill": {
     "duration": 0.045267,
     "end_time": "2021-10-18T19:10:30.187129",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.141862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 14,219,781 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "        calculates the number of trainable parameters.\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2526840f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.267039Z",
     "iopub.status.busy": "2021-10-18T19:10:30.265404Z",
     "iopub.status.idle": "2021-10-18T19:10:30.267695Z",
     "shell.execute_reply": "2021-10-18T19:10:30.268111Z",
     "shell.execute_reply.started": "2021-10-18T19:05:59.779806Z"
    },
    "papermill": {
     "duration": 0.043693,
     "end_time": "2021-10-18T19:10:30.268249",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.224556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "958d29d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.349335Z",
     "iopub.status.busy": "2021-10-18T19:10:30.348463Z",
     "iopub.status.idle": "2021-10-18T19:10:30.350940Z",
     "shell.execute_reply": "2021-10-18T19:10:30.350489Z",
     "shell.execute_reply.started": "2021-10-18T19:05:59.791017Z"
    },
    "papermill": {
     "duration": 0.044079,
     "end_time": "2021-10-18T19:10:30.351046",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.306967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "# NOTE: Our loss function calculates the average loss per token, \n",
    "# however by passing the index of the <pad> token as the ignore_index argument \n",
    "# we ignore the loss whenever the target token is a padding token.\n",
    "\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434fe076",
   "metadata": {
    "papermill": {
     "duration": 0.037726,
     "end_time": "2021-10-18T19:10:30.425692",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.387966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "495b4af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.506798Z",
     "iopub.status.busy": "2021-10-18T19:10:30.506218Z",
     "iopub.status.idle": "2021-10-18T19:10:30.509439Z",
     "shell.execute_reply": "2021-10-18T19:10:30.510023Z",
     "shell.execute_reply.started": "2021-10-18T19:07:46.052841Z"
    },
    "papermill": {
     "duration": 0.047829,
     "end_time": "2021-10-18T19:10:30.510161",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.462332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # trg.shape => (trg_len, batch_size)\n",
    "        # output.shape => (trg_len, batch_size, output_dim)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # We have removed the <sos> token\n",
    "        # trg.shape => ((trg_len - 1) * batch_size)\n",
    "        # output.shape => ((trg_len - 1) * batch_size, output_dim)\n",
    "        \n",
    "        # NOTE:  the loss function only works on 2d inputs with 1d targets\n",
    "        # we need to flatten each of them with .view\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24241493",
   "metadata": {
    "papermill": {
     "duration": 0.037836,
     "end_time": "2021-10-18T19:10:30.585111",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.547275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a9c981b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.667379Z",
     "iopub.status.busy": "2021-10-18T19:10:30.666484Z",
     "iopub.status.idle": "2021-10-18T19:10:30.668403Z",
     "shell.execute_reply": "2021-10-18T19:10:30.668848Z",
     "shell.execute_reply.started": "2021-10-18T19:06:03.488606Z"
    },
    "papermill": {
     "duration": 0.046837,
     "end_time": "2021-10-18T19:10:30.668985",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.622148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) # turn off teacher forcing\n",
    "            \n",
    "            # trg.shape => (trg_len, batch_size)\n",
    "            # output.shape => (trg_len, batch_size, output_dim)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # We have removed the <sos> token\n",
    "            # trg.shape => ((trg_len - 1) * batch_size)\n",
    "            # output.shape => ((trg_len - 1) * batch_size, output_dim)\n",
    "\n",
    "            # NOTE:  the loss function only works on 2d inputs with 1d targets\n",
    "            # we need to flatten each of them with .view\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3abf13ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.747657Z",
     "iopub.status.busy": "2021-10-18T19:10:30.746853Z",
     "iopub.status.idle": "2021-10-18T19:10:30.748994Z",
     "shell.execute_reply": "2021-10-18T19:10:30.749400Z",
     "shell.execute_reply.started": "2021-10-18T19:06:04.466520Z"
    },
    "papermill": {
     "duration": 0.043671,
     "end_time": "2021-10-18T19:10:30.749539",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.705868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9574f0",
   "metadata": {
    "papermill": {
     "duration": 0.036552,
     "end_time": "2021-10-18T19:10:30.823211",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.786659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0a1a9c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:10:30.929448Z",
     "iopub.status.busy": "2021-10-18T19:10:30.918819Z",
     "iopub.status.idle": "2021-10-18T19:16:31.037479Z",
     "shell.execute_reply": "2021-10-18T19:16:31.038014Z",
     "shell.execute_reply.started": "2021-10-18T19:07:51.292727Z"
    },
    "papermill": {
     "duration": 360.178498,
     "end_time": "2021-10-18T19:16:31.038179",
     "exception": false,
     "start_time": "2021-10-18T19:10:30.859681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 37s\n",
      "\tTrain Loss: 5.072 | Train PPL: 159.506\n",
      "\t Val. Loss: 5.385 |  Val. PPL: 218.059\n",
      "Epoch: 02 | Time: 0m 35s\n",
      "\tTrain Loss: 4.383 | Train PPL:  80.039\n",
      "\t Val. Loss: 5.134 |  Val. PPL: 169.613\n",
      "Epoch: 03 | Time: 0m 35s\n",
      "\tTrain Loss: 4.017 | Train PPL:  55.517\n",
      "\t Val. Loss: 4.653 |  Val. PPL: 104.866\n",
      "Epoch: 04 | Time: 0m 35s\n",
      "\tTrain Loss: 3.630 | Train PPL:  37.715\n",
      "\t Val. Loss: 4.255 |  Val. PPL:  70.422\n",
      "Epoch: 05 | Time: 0m 35s\n",
      "\tTrain Loss: 3.282 | Train PPL:  26.639\n",
      "\t Val. Loss: 4.028 |  Val. PPL:  56.134\n",
      "Epoch: 06 | Time: 0m 35s\n",
      "\tTrain Loss: 2.988 | Train PPL:  19.853\n",
      "\t Val. Loss: 3.873 |  Val. PPL:  48.109\n",
      "Epoch: 07 | Time: 0m 35s\n",
      "\tTrain Loss: 2.744 | Train PPL:  15.544\n",
      "\t Val. Loss: 3.702 |  Val. PPL:  40.509\n",
      "Epoch: 08 | Time: 0m 35s\n",
      "\tTrain Loss: 2.503 | Train PPL:  12.219\n",
      "\t Val. Loss: 3.623 |  Val. PPL:  37.462\n",
      "Epoch: 09 | Time: 0m 35s\n",
      "\tTrain Loss: 2.289 | Train PPL:   9.862\n",
      "\t Val. Loss: 3.604 |  Val. PPL:  36.734\n",
      "Epoch: 10 | Time: 0m 36s\n",
      "\tTrain Loss: 2.130 | Train PPL:   8.417\n",
      "\t Val. Loss: 3.621 |  Val. PPL:  37.384\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c79d0af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-18T19:16:31.123192Z",
     "iopub.status.busy": "2021-10-18T19:16:31.121476Z",
     "iopub.status.idle": "2021-10-18T19:16:31.489675Z",
     "shell.execute_reply": "2021-10-18T19:16:31.490102Z",
     "shell.execute_reply.started": "2021-10-18T19:09:03.100960Z"
    },
    "papermill": {
     "duration": 0.411708,
     "end_time": "2021-10-18T19:16:31.490251",
     "exception": false,
     "start_time": "2021-10-18T19:16:31.078543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.562 | Test PPL:  35.237 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut2-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4463950",
   "metadata": {
    "papermill": {
     "duration": 0.039729,
     "end_time": "2021-10-18T19:16:31.569563",
     "exception": false,
     "start_time": "2021-10-18T19:16:31.529834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 423.565065,
   "end_time": "2021-10-18T19:16:35.164332",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-18T19:09:31.599267",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
