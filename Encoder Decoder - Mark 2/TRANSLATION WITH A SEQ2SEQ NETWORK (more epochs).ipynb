{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162bf11a",
   "metadata": {
    "papermill": {
     "duration": 0.022515,
     "end_time": "2021-09-19T14:01:14.973007",
     "exception": false,
     "start_time": "2021-09-19T14:01:14.950492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc38ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:15.021566Z",
     "iopub.status.busy": "2021-09-19T14:01:15.020057Z",
     "iopub.status.idle": "2021-09-19T14:01:15.101050Z",
     "shell.execute_reply": "2021-09-19T14:01:15.100499Z",
     "shell.execute_reply.started": "2021-09-19T13:16:16.736672Z"
    },
    "papermill": {
     "duration": 0.106242,
     "end_time": "2021-09-19T14:01:15.101196",
     "exception": false,
     "start_time": "2021-09-19T14:01:14.994954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dbba28e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:15.149995Z",
     "iopub.status.busy": "2021-09-19T14:01:15.147407Z",
     "iopub.status.idle": "2021-09-19T14:01:19.581604Z",
     "shell.execute_reply": "2021-09-19T14:01:19.583047Z",
     "shell.execute_reply.started": "2021-09-19T12:58:54.807146Z"
    },
    "papermill": {
     "duration": 4.460512,
     "end_time": "2021-09-19T14:01:19.583348",
     "exception": false,
     "start_time": "2021-09-19T14:01:15.122836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36beb5e9",
   "metadata": {
    "papermill": {
     "duration": 0.036528,
     "end_time": "2021-09-19T14:01:19.665644",
     "exception": false,
     "start_time": "2021-09-19T14:01:19.629116",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Lang Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "490dc888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:19.749416Z",
     "iopub.status.busy": "2021-09-19T14:01:19.741547Z",
     "iopub.status.idle": "2021-09-19T14:01:19.754467Z",
     "shell.execute_reply": "2021-09-19T14:01:19.755222Z",
     "shell.execute_reply.started": "2021-09-19T13:02:50.232844Z"
    },
    "papermill": {
     "duration": 0.050472,
     "end_time": "2021-09-19T14:01:19.755424",
     "exception": false,
     "start_time": "2021-09-19T14:01:19.704952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            0:\"SOS\",\n",
    "            1:\"EOS\"\n",
    "        }\n",
    "        self.n_words = 2 # Just SOS and EOS\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        \"\"\"\n",
    "        adds each word of the sentence in vocab\n",
    "        \n",
    "        :param sentence: a sentence of words\n",
    "        \"\"\"\n",
    "        \n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        \"\"\"\n",
    "        adds the word in vocab\n",
    "        \n",
    "        :param word: the word to be added\n",
    "        \"\"\"\n",
    "        \n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039b4d82",
   "metadata": {
    "papermill": {
     "duration": 0.034394,
     "end_time": "2021-09-19T14:01:19.824685",
     "exception": false,
     "start_time": "2021-09-19T14:01:19.790291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Some preprocessing Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d712aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:19.901297Z",
     "iopub.status.busy": "2021-09-19T14:01:19.900592Z",
     "iopub.status.idle": "2021-09-19T14:01:19.902601Z",
     "shell.execute_reply": "2021-09-19T14:01:19.903078Z",
     "shell.execute_reply.started": "2021-09-19T13:03:00.673085Z"
    },
    "papermill": {
     "duration": 0.043801,
     "end_time": "2021-09-19T14:01:19.903201",
     "exception": false,
     "start_time": "2021-09-19T14:01:19.859400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn a unicode string to plain ASCII\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b69e50",
   "metadata": {
    "papermill": {
     "duration": 0.035127,
     "end_time": "2021-09-19T14:01:19.972996",
     "exception": false,
     "start_time": "2021-09-19T14:01:19.937869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**To read the data file we will split the file into lines, and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English. The reverse flag is used to reverse the pairs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927ade64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:20.053486Z",
     "iopub.status.busy": "2021-09-19T14:01:20.052681Z",
     "iopub.status.idle": "2021-09-19T14:01:20.055600Z",
     "shell.execute_reply": "2021-09-19T14:01:20.056079Z",
     "shell.execute_reply.started": "2021-09-19T13:03:38.552963Z"
    },
    "papermill": {
     "duration": 0.046658,
     "end_time": "2021-09-19T14:01:20.056201",
     "exception": false,
     "start_time": "2021-09-19T14:01:20.009543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1=\"eng\", lang2=\"fra\", reverse=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param lang1: the language to be translated.\n",
    "    :param lang2: the language to be translated to.\n",
    "    :param reverse: reverse the scenario\n",
    "    \n",
    "    What this function does is, it will return the instances\n",
    "    of `Lang` class for each language and the corresponding\n",
    "    lang1-lang2 pairs.\n",
    "    \n",
    "    like :\n",
    "    Eng - French pairs\n",
    "    \"I am cold.   J'ai froid.\" => [\"I am cold.\", \"J'ai froid.\"]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reading Lines...\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(f\"../input/english-french-dataset/data/{lang1}-{lang2}.txt\", \n",
    "                encoding='utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "        \n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8105f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:20.133783Z",
     "iopub.status.busy": "2021-09-19T14:01:20.133007Z",
     "iopub.status.idle": "2021-09-19T14:01:20.137841Z",
     "shell.execute_reply": "2021-09-19T14:01:20.138441Z",
     "shell.execute_reply.started": "2021-09-19T13:04:03.565945Z"
    },
    "papermill": {
     "duration": 0.047285,
     "end_time": "2021-09-19T14:01:20.138635",
     "exception": false,
     "start_time": "2021-09-19T14:01:20.091350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "# We are sampling some sentences so that, we can test the model fast\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    \"\"\"\n",
    "    a function to tell whether to,\n",
    "    filter the given pair p.\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    \"\"\"\n",
    "    filter the given pairs and include if meets the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188fcb08",
   "metadata": {
    "papermill": {
     "duration": 0.021421,
     "end_time": "2021-09-19T14:01:20.185264",
     "exception": false,
     "start_time": "2021-09-19T14:01:20.163843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The full process for preparing the data is:\n",
    "\n",
    "* Read text file and split into lines, split lines into pairs\n",
    "* Normalize text, filter by length and content\n",
    "* Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8908cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:20.234640Z",
     "iopub.status.busy": "2021-09-19T14:01:20.234127Z",
     "iopub.status.idle": "2021-09-19T14:01:25.430570Z",
     "shell.execute_reply": "2021-09-19T14:01:25.429599Z",
     "shell.execute_reply.started": "2021-09-19T13:04:43.218117Z"
    },
    "papermill": {
     "duration": 5.22403,
     "end_time": "2021-09-19T14:01:25.430736",
     "exception": false,
     "start_time": "2021-09-19T14:01:20.206706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lines...\n",
      "Read 135842 sentenc pairs\n",
      "Trimmed to 9874 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 3802\n",
      "eng 2689\n",
      "['j y travaille .', 'i m working on it .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    print(f\"Read {len(pairs)} sentenc pairs\")\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca9f05f",
   "metadata": {
    "papermill": {
     "duration": 0.02282,
     "end_time": "2021-09-19T14:01:25.476539",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.453719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e3a72a",
   "metadata": {
    "papermill": {
     "duration": 0.023221,
     "end_time": "2021-09-19T14:01:25.521864",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.498643",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ENCODER CLASS\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e10d4c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:25.577679Z",
     "iopub.status.busy": "2021-09-19T14:01:25.576872Z",
     "iopub.status.idle": "2021-09-19T14:01:25.578948Z",
     "shell.execute_reply": "2021-09-19T14:01:25.579390Z",
     "shell.execute_reply.started": "2021-09-19T13:05:35.863116Z"
    },
    "papermill": {
     "duration": 0.034461,
     "end_time": "2021-09-19T14:01:25.579530",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.545069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size: the size of the vocab of \n",
    "            lang to be translated.\n",
    "        :param hidden_size: the output dim of the emb vector\n",
    "            also, the size of the hidden vector in RNN\n",
    "        \"\"\"\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        :param x: the input of shape [batch_size, seq_len]\n",
    "        :param hidden: the hidden matrix for RNN\n",
    "        \"\"\"\n",
    "        \n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        # shape (1, 1, batch_size * seq_len * embedding_size)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8e03a",
   "metadata": {
    "papermill": {
     "duration": 0.021683,
     "end_time": "2021-09-19T14:01:25.623234",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.601551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DECODER CLASS\n",
    "### (*simple decoder*)\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ceb28f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:25.670815Z",
     "iopub.status.busy": "2021-09-19T14:01:25.670031Z",
     "iopub.status.idle": "2021-09-19T14:01:25.678280Z",
     "shell.execute_reply": "2021-09-19T14:01:25.677858Z",
     "shell.execute_reply.started": "2021-09-19T13:06:10.731515Z"
    },
    "papermill": {
     "duration": 0.033256,
     "end_time": "2021-09-19T14:01:25.678399",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.645143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size: the output dim of the emb vector\n",
    "            also, the size of the hidden vector in RNN\n",
    "        :param output_size: the size of the vocab of \n",
    "            lang to be translated to.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hiddem_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        :param x: the input of shape [batch_size, seq_len]\n",
    "        :param hidden: the hidden matrix for RNN\n",
    "        \"\"\"\n",
    "        \n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        # shape (1, 1, batch_size * seq_len * embedding_size)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a4382",
   "metadata": {
    "papermill": {
     "duration": 0.021894,
     "end_time": "2021-09-19T14:01:25.722317",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.700423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *ATTENTION* DECODER CLASS\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b34b633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:25.778436Z",
     "iopub.status.busy": "2021-09-19T14:01:25.777636Z",
     "iopub.status.idle": "2021-09-19T14:01:25.779957Z",
     "shell.execute_reply": "2021-09-19T14:01:25.779564Z",
     "shell.execute_reply.started": "2021-09-19T13:09:48.055354Z"
    },
    "papermill": {
     "duration": 0.035705,
     "end_time": "2021-09-19T14:01:25.780061",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.744356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size, \n",
    "                 dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        \"\"\"\n",
    "        :param hidden_size: the hidden matrix for RNN\n",
    "        :param output_size: the size of the vocab of \n",
    "            lang to be translated to.\n",
    "        :param dropout_p: dropout probability\n",
    "        :param max_length: the maximum length of the sequence\n",
    "        \"\"\"\n",
    "        \n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param x: the input tensor for the decoder (used only for training)\n",
    "        :param hidden: the hidden context vectors\n",
    "        :param encoder_outputs: the encoder outputs for the sentence\n",
    "        \"\"\"\n",
    "        \n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        # shape (1, 1, batch_size * seq_len * embedding_size)\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # Concatenating the previous hidden and the encoder outputs\n",
    "        # Then calculating the `attention weights`\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)),\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        # Applying attention: multiplying the corresponding attention\n",
    "        # with the encoder output\n",
    "        attn_applied = torch.bmm(\n",
    "            attn_weights.unsqueeze(0),\n",
    "            encoder_outputs.unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Concatenating the ``Word to be predicted`` embedding\n",
    "        # with the ``attention applied`` encoder vectors\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # at first, this hidden is the context vector from the encoder\n",
    "        # after that, we will pass this hidden, as the ``decoder hidden`` context vector\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        # This output goes towards predicting the required translated word\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f8688c",
   "metadata": {
    "papermill": {
     "duration": 0.021834,
     "end_time": "2021-09-19T14:01:25.823711",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.801877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d35a19",
   "metadata": {
    "papermill": {
     "duration": 0.021701,
     "end_time": "2021-09-19T14:01:25.867474",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.845773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd145f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:25.918393Z",
     "iopub.status.busy": "2021-09-19T14:01:25.917591Z",
     "iopub.status.idle": "2021-09-19T14:01:25.919550Z",
     "shell.execute_reply": "2021-09-19T14:01:25.919958Z",
     "shell.execute_reply.started": "2021-09-19T13:09:54.640143Z"
    },
    "papermill": {
     "duration": 0.030651,
     "end_time": "2021-09-19T14:01:25.920077",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.889426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    converts the words of a sentence to a list of indexes\n",
    "    \"\"\"\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    converts the sentence to it's corresponding Tensor\n",
    "    \"\"\"\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    \"\"\"\n",
    "    transform the sentences in the pair\n",
    "    \n",
    "    e.g:\n",
    "        [\"I am cold.\", \"J'ai froid.\"] --> ([34, 88, 91], [22, 45, 97])\n",
    "    \"\"\"\n",
    "    \n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    \n",
    "    return (input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcbc4a",
   "metadata": {
    "papermill": {
     "duration": 0.021948,
     "end_time": "2021-09-19T14:01:25.963924",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.941976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06868835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.021736Z",
     "iopub.status.busy": "2021-09-19T14:01:26.020152Z",
     "iopub.status.idle": "2021-09-19T14:01:26.023627Z",
     "shell.execute_reply": "2021-09-19T14:01:26.024014Z",
     "shell.execute_reply.started": "2021-09-19T13:09:55.94308Z"
    },
    "papermill": {
     "duration": 0.038312,
     "end_time": "2021-09-19T14:01:26.024132",
     "exception": false,
     "start_time": "2021-09-19T14:01:25.985820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_force_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param input_tensor: the input sequence\n",
    "    :param target_tensor: the target sequence\n",
    "    :param encoder: the Encoder\n",
    "    :param decoder: the Decoder\n",
    "    :param encoder_optimizer: the optimizer used for Encoder\n",
    "    :param decoder_optimizer: the optimizer used for Decoder\n",
    "    :param criterion: the loss function used\n",
    "    :param max_length: the max length of the sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden\n",
    "        )\n",
    "        \n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_force_ratio else False\n",
    "        \n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Feed the target as the next input\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        # Use own prediction as the next input\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            # topk : k largest\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "                \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae9a6724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.073396Z",
     "iopub.status.busy": "2021-09-19T14:01:26.072674Z",
     "iopub.status.idle": "2021-09-19T14:01:26.075113Z",
     "shell.execute_reply": "2021-09-19T14:01:26.074680Z",
     "shell.execute_reply.started": "2021-09-19T13:09:56.171275Z"
    },
    "papermill": {
     "duration": 0.029204,
     "end_time": "2021-09-19T14:01:26.075222",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.046018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  a helper function to print time elapsed and estimated time \n",
    "# remaining given the current time and progress %.\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c550a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.122083Z",
     "iopub.status.busy": "2021-09-19T14:01:26.121291Z",
     "iopub.status.idle": "2021-09-19T14:01:26.130665Z",
     "shell.execute_reply": "2021-09-19T14:01:26.130224Z",
     "shell.execute_reply.started": "2021-09-19T13:09:56.391508Z"
    },
    "papermill": {
     "duration": 0.033561,
     "end_time": "2021-09-19T14:01:26.130771",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.097210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, \n",
    "               learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    :param encoder: the Encoder\n",
    "    :param decoder: the Decoder\n",
    "    :param n_iters: the number of epochs\n",
    "    :param print_every: print every 100th result\n",
    "    :param plot_every: plot every 100th result\n",
    "    :param learning_rate: the learning rate to be applied\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    \n",
    "    print_loss_total = 0 # Reset at every print_every\n",
    "    plot_loss_total = 0 # Reset at every plot_every\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                     for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, \n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            \n",
    "        \n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5cb99",
   "metadata": {
    "papermill": {
     "duration": 0.02189,
     "end_time": "2021-09-19T14:01:26.174528",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.152638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02019d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.224340Z",
     "iopub.status.busy": "2021-09-19T14:01:26.223501Z",
     "iopub.status.idle": "2021-09-19T14:01:26.225920Z",
     "shell.execute_reply": "2021-09-19T14:01:26.225507Z",
     "shell.execute_reply.started": "2021-09-19T13:10:29.787818Z"
    },
    "papermill": {
     "duration": 0.029473,
     "end_time": "2021-09-19T14:01:26.226018",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.196545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1dadac",
   "metadata": {
    "papermill": {
     "duration": 0.021725,
     "end_time": "2021-09-19T14:01:26.270225",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.248500",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2944759c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.323331Z",
     "iopub.status.busy": "2021-09-19T14:01:26.317993Z",
     "iopub.status.idle": "2021-09-19T14:01:26.325626Z",
     "shell.execute_reply": "2021-09-19T14:01:26.325210Z",
     "shell.execute_reply.started": "2021-09-19T13:12:14.810382Z"
    },
    "papermill": {
     "duration": 0.033541,
     "end_time": "2021-09-19T14:01:26.325727",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.292186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, \n",
    "             max_length=MAX_LENGTH):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param encoder: the Encoder\n",
    "    :param decoder: the Decoder\n",
    "    :param sentence: the input sentence\n",
    "    :param max_length: the max length of the sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, \n",
    "                                      device=device)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            \n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], \n",
    "                                                     encoder_hidden)\n",
    "            \n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoded_words = []\n",
    "        \n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "                \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69206ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.374937Z",
     "iopub.status.busy": "2021-09-19T14:01:26.374136Z",
     "iopub.status.idle": "2021-09-19T14:01:26.376127Z",
     "shell.execute_reply": "2021-09-19T14:01:26.376556Z",
     "shell.execute_reply.started": "2021-09-19T13:12:17.208957Z"
    },
    "papermill": {
     "duration": 0.029093,
     "end_time": "2021-09-19T14:01:26.376672",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.347579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate Randomly\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        \n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c516d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:01:26.424816Z",
     "iopub.status.busy": "2021-09-19T14:01:26.424322Z",
     "iopub.status.idle": "2021-09-19T14:26:49.876542Z",
     "shell.execute_reply": "2021-09-19T14:26:49.875546Z",
     "shell.execute_reply.started": "2021-09-19T13:14:20.278082Z"
    },
    "papermill": {
     "duration": 1523.477927,
     "end_time": "2021-09-19T14:26:49.876672",
     "exception": false,
     "start_time": "2021-09-19T14:01:26.398745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 44s (- 24m 16s) (5000 6%) 2.8365\n",
      "3m 24s (- 22m 6s) (10000 13%) 2.2768\n",
      "5m 5s (- 20m 20s) (15000 20%) 1.9481\n",
      "6m 45s (- 18m 35s) (20000 26%) 1.7018\n",
      "8m 26s (- 16m 52s) (25000 33%) 1.4920\n",
      "10m 6s (- 15m 9s) (30000 40%) 1.3142\n",
      "11m 46s (- 13m 27s) (35000 46%) 1.1731\n",
      "13m 28s (- 11m 47s) (40000 53%) 1.0712\n",
      "15m 9s (- 10m 6s) (45000 60%) 0.9393\n",
      "16m 50s (- 8m 25s) (50000 66%) 0.8342\n",
      "18m 31s (- 6m 44s) (55000 73%) 0.7749\n",
      "20m 12s (- 5m 3s) (60000 80%) 0.7180\n",
      "21m 54s (- 3m 22s) (65000 86%) 0.6218\n",
      "23m 35s (- 1m 41s) (70000 93%) 0.5676\n",
      "25m 17s (- 0m 0s) (75000 100%) 0.5190\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3e8adcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:26:49.934702Z",
     "iopub.status.busy": "2021-09-19T14:26:49.933851Z",
     "iopub.status.idle": "2021-09-19T14:26:50.021764Z",
     "shell.execute_reply": "2021-09-19T14:26:50.022153Z",
     "shell.execute_reply.started": "2021-09-19T13:14:28.891813Z"
    },
    "papermill": {
     "duration": 0.119353,
     "end_time": "2021-09-19T14:26:50.022333",
     "exception": false,
     "start_time": "2021-09-19T14:26:49.902980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis cultive e .\n",
      "= i m cultured .\n",
      "< i m cultured . <EOS>\n",
      "\n",
      "> il mai trise la nouvelle technique .\n",
      "= he s got the new technique down pat .\n",
      "< he s in the new new pool . <EOS>\n",
      "\n",
      "> on retourne a la case de part .\n",
      "= we re going back to square one .\n",
      "< we re going to to the one . <EOS>\n",
      "\n",
      "> je suis habitue a tom maintenant .\n",
      "= i m used to tom now .\n",
      "< i m used to now now . <EOS>\n",
      "\n",
      "> je suis pre t a de marrer .\n",
      "= i m ready to start .\n",
      "< i m ready to start . <EOS>\n",
      "\n",
      "> vous n e tes pas encore mortes .\n",
      "= you re not dead yet .\n",
      "< you re not dead yet . <EOS>\n",
      "\n",
      "> j ai toujours faim .\n",
      "= i m always hungry .\n",
      "< i m always hungry . <EOS>\n",
      "\n",
      "> nous travaillons dans un budget limite .\n",
      "= we re working on a limited budget .\n",
      "< we are working a a couple . <EOS>\n",
      "\n",
      "> tu es tellement pre visible !\n",
      "= you re so predictable .\n",
      "< you re so predictable . <EOS>\n",
      "\n",
      "> vous mentez mal .\n",
      "= you re a bad liar .\n",
      "< you re a bad liar . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce8d4f3",
   "metadata": {
    "papermill": {
     "duration": 0.026472,
     "end_time": "2021-09-19T14:26:50.075787",
     "exception": false,
     "start_time": "2021-09-19T14:26:50.049315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualising Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba3322a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:26:50.132958Z",
     "iopub.status.busy": "2021-09-19T14:26:50.131718Z",
     "iopub.status.idle": "2021-09-19T14:26:50.226339Z",
     "shell.execute_reply": "2021-09-19T14:26:50.227068Z",
     "shell.execute_reply.started": "2021-09-19T13:14:32.327735Z"
    },
    "papermill": {
     "duration": 0.125271,
     "end_time": "2021-09-19T14:26:50.227302",
     "exception": false,
     "start_time": "2021-09-19T14:26:50.102031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2840b60710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92152e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T14:26:50.325216Z",
     "iopub.status.busy": "2021-09-19T14:26:50.324382Z",
     "iopub.status.idle": "2021-09-19T14:26:50.958287Z",
     "shell.execute_reply": "2021-09-19T14:26:50.958975Z",
     "shell.execute_reply.started": "2021-09-19T13:16:23.118368Z"
    },
    "papermill": {
     "duration": 0.684146,
     "end_time": "2021-09-19T14:26:50.959206",
     "exception": false,
     "start_time": "2021-09-19T14:26:50.275060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she is five years younger than me . <EOS>\n",
      "input = elle est trop petit .\n",
      "output = she s too short . <EOS>\n",
      "input = je ne crains pas de mourir .\n",
      "output = i m not afraid to die . <EOS>\n",
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a talented young . <EOS>\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433602c6",
   "metadata": {
    "papermill": {
     "duration": 0.04705,
     "end_time": "2021-09-19T14:26:51.055041",
     "exception": false,
     "start_time": "2021-09-19T14:26:51.007991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1544.163501,
   "end_time": "2021-09-19T14:26:52.666502",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-19T14:01:08.503001",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
