{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de242b14",
   "metadata": {
    "papermill": {
     "duration": 0.029248,
     "end_time": "2021-09-19T13:17:14.316464",
     "exception": false,
     "start_time": "2021-09-19T13:17:14.287216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0937946c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:14.453207Z",
     "iopub.status.busy": "2021-09-19T13:17:14.452100Z",
     "iopub.status.idle": "2021-09-19T13:17:14.457276Z",
     "shell.execute_reply": "2021-09-19T13:17:14.457810Z",
     "shell.execute_reply.started": "2021-09-19T13:16:16.736672Z"
    },
    "papermill": {
     "duration": 0.111634,
     "end_time": "2021-09-19T13:17:14.458136",
     "exception": false,
     "start_time": "2021-09-19T13:17:14.346502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b312620",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:14.522300Z",
     "iopub.status.busy": "2021-09-19T13:17:14.521662Z",
     "iopub.status.idle": "2021-09-19T13:17:19.110439Z",
     "shell.execute_reply": "2021-09-19T13:17:19.109784Z",
     "shell.execute_reply.started": "2021-09-19T12:58:54.807146Z"
    },
    "papermill": {
     "duration": 4.62431,
     "end_time": "2021-09-19T13:17:19.110587",
     "exception": false,
     "start_time": "2021-09-19T13:17:14.486277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc06a9",
   "metadata": {
    "papermill": {
     "duration": 0.027166,
     "end_time": "2021-09-19T13:17:19.167738",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.140572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Lang Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4955386b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:19.233273Z",
     "iopub.status.busy": "2021-09-19T13:17:19.232144Z",
     "iopub.status.idle": "2021-09-19T13:17:19.235420Z",
     "shell.execute_reply": "2021-09-19T13:17:19.234904Z",
     "shell.execute_reply.started": "2021-09-19T13:02:50.232844Z"
    },
    "papermill": {
     "duration": 0.040057,
     "end_time": "2021-09-19T13:17:19.235546",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.195489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {\n",
    "            0:\"SOS\",\n",
    "            1:\"EOS\"\n",
    "        }\n",
    "        self.n_words = 2 # Just SOS and EOS\n",
    "        \n",
    "    def addSentence(self, sentence):\n",
    "        \"\"\"\n",
    "        adds each word of the sentence in vocab\n",
    "        \n",
    "        :param sentence: a sentence of words\n",
    "        \"\"\"\n",
    "        \n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        \"\"\"\n",
    "        adds the word in vocab\n",
    "        \n",
    "        :param word: the word to be added\n",
    "        \"\"\"\n",
    "        \n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b7a4e",
   "metadata": {
    "papermill": {
     "duration": 0.02761,
     "end_time": "2021-09-19T13:17:19.291040",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.263430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Some preprocessing Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3cb16d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:19.355315Z",
     "iopub.status.busy": "2021-09-19T13:17:19.354192Z",
     "iopub.status.idle": "2021-09-19T13:17:19.357258Z",
     "shell.execute_reply": "2021-09-19T13:17:19.356728Z",
     "shell.execute_reply.started": "2021-09-19T13:03:00.673085Z"
    },
    "papermill": {
     "duration": 0.038343,
     "end_time": "2021-09-19T13:17:19.357405",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.319062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn a unicode string to plain ASCII\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category != 'Mn'\n",
    "    )\n",
    "\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12401e",
   "metadata": {
    "papermill": {
     "duration": 0.026984,
     "end_time": "2021-09-19T13:17:19.412568",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.385584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**To read the data file we will split the file into lines, and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English. The reverse flag is used to reverse the pairs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0829da74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:19.476394Z",
     "iopub.status.busy": "2021-09-19T13:17:19.475316Z",
     "iopub.status.idle": "2021-09-19T13:17:19.477932Z",
     "shell.execute_reply": "2021-09-19T13:17:19.478404Z",
     "shell.execute_reply.started": "2021-09-19T13:03:38.552963Z"
    },
    "papermill": {
     "duration": 0.038747,
     "end_time": "2021-09-19T13:17:19.478547",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.439800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1=\"eng\", lang2=\"fra\", reverse=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param lang1: the language to be translated.\n",
    "    :param lang2: the language to be translated to.\n",
    "    :param reverse: reverse the scenario\n",
    "    \n",
    "    What this function does is, it will return the instances\n",
    "    of `Lang` class for each language and the corresponding\n",
    "    lang1-lang2 pairs.\n",
    "    \n",
    "    like :\n",
    "    Eng - French pairs\n",
    "    \"I am cold.   J'ai froid.\" => [\"I am cold.\", \"J'ai froid.\"]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Reading Lines...\")\n",
    "    \n",
    "    # Read the file and split into lines\n",
    "    lines = open(f\"../input/english-french-dataset/data/{lang1}-{lang2}.txt\", \n",
    "                encoding='utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "        \n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "        \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4cf0fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:19.542538Z",
     "iopub.status.busy": "2021-09-19T13:17:19.541532Z",
     "iopub.status.idle": "2021-09-19T13:17:19.544143Z",
     "shell.execute_reply": "2021-09-19T13:17:19.544637Z",
     "shell.execute_reply.started": "2021-09-19T13:04:03.565945Z"
    },
    "papermill": {
     "duration": 0.038896,
     "end_time": "2021-09-19T13:17:19.544775",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.505879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "# We are sampling some sentences so that, we can test the model fast\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    \"\"\"\n",
    "    a function to tell whether to,\n",
    "    filter the given pair p.\n",
    "    \"\"\"\n",
    "    \n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "            len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "            p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    \"\"\"\n",
    "    filter the given pairs and include if meets the criteria.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d7319",
   "metadata": {
    "papermill": {
     "duration": 0.027772,
     "end_time": "2021-09-19T13:17:19.600714",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.572942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The full process for preparing the data is:\n",
    "\n",
    "* Read text file and split into lines, split lines into pairs\n",
    "* Normalize text, filter by length and content\n",
    "* Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee5f8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:19.664310Z",
     "iopub.status.busy": "2021-09-19T13:17:19.663548Z",
     "iopub.status.idle": "2021-09-19T13:17:26.522058Z",
     "shell.execute_reply": "2021-09-19T13:17:26.521373Z",
     "shell.execute_reply.started": "2021-09-19T13:04:43.218117Z"
    },
    "papermill": {
     "duration": 6.893684,
     "end_time": "2021-09-19T13:17:26.522231",
     "exception": false,
     "start_time": "2021-09-19T13:17:19.628547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Lines...\n",
      "Read 135842 sentenc pairs\n",
      "Trimmed to 9874 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 3802\n",
      "eng 2689\n",
      "['je t aide quand tu veux .', 'i am always ready to help you .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    \n",
    "    print(f\"Read {len(pairs)} sentenc pairs\")\n",
    "    \n",
    "    pairs = filterPairs(pairs)\n",
    "    print(f\"Trimmed to {len(pairs)} sentence pairs\")\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    \n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07310119",
   "metadata": {
    "papermill": {
     "duration": 0.028794,
     "end_time": "2021-09-19T13:17:26.580673",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.551879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## The Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc588ac3",
   "metadata": {
    "papermill": {
     "duration": 0.028742,
     "end_time": "2021-09-19T13:17:26.639185",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.610443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ENCODER CLASS\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed78612d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:26.707801Z",
     "iopub.status.busy": "2021-09-19T13:17:26.706873Z",
     "iopub.status.idle": "2021-09-19T13:17:26.710970Z",
     "shell.execute_reply": "2021-09-19T13:17:26.709628Z",
     "shell.execute_reply.started": "2021-09-19T13:05:35.863116Z"
    },
    "papermill": {
     "duration": 0.042135,
     "end_time": "2021-09-19T13:17:26.711135",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.669000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        \"\"\"\n",
    "        :param input_size: the size of the vocab of \n",
    "            lang to be translated.\n",
    "        :param hidden_size: the output dim of the emb vector\n",
    "            also, the size of the hidden vector in RNN\n",
    "        \"\"\"\n",
    "        \n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        :param x: the input of shape [batch_size, seq_len]\n",
    "        :param hidden: the hidden matrix for RNN\n",
    "        \"\"\"\n",
    "        \n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        # shape (1, 1, batch_size * seq_len * embedding_size)\n",
    "        \n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbaa7ad",
   "metadata": {
    "papermill": {
     "duration": 0.028746,
     "end_time": "2021-09-19T13:17:26.768528",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.739782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DECODER CLASS\n",
    "### (*simple decoder*)\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016a01c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:26.835211Z",
     "iopub.status.busy": "2021-09-19T13:17:26.833467Z",
     "iopub.status.idle": "2021-09-19T13:17:26.838083Z",
     "shell.execute_reply": "2021-09-19T13:17:26.838608Z",
     "shell.execute_reply.started": "2021-09-19T13:06:10.731515Z"
    },
    "papermill": {
     "duration": 0.042296,
     "end_time": "2021-09-19T13:17:26.838752",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.796456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        \"\"\"\n",
    "        :param hidden_size: the output dim of the emb vector\n",
    "            also, the size of the hidden vector in RNN\n",
    "        :param output_size: the size of the vocab of \n",
    "            lang to be translated to.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hiddem_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        :param x: the input of shape [batch_size, seq_len]\n",
    "        :param hidden: the hidden matrix for RNN\n",
    "        \"\"\"\n",
    "        \n",
    "        output = self.embedding(x).view(1, 1, -1)\n",
    "        # shape (1, 1, batch_size * seq_len * embedding_size)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6e68f0",
   "metadata": {
    "papermill": {
     "duration": 0.028306,
     "end_time": "2021-09-19T13:17:26.895707",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.867401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## *ATTENTION* DECODER CLASS\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a8abbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:26.969624Z",
     "iopub.status.busy": "2021-09-19T13:17:26.968558Z",
     "iopub.status.idle": "2021-09-19T13:17:26.971807Z",
     "shell.execute_reply": "2021-09-19T13:17:26.971220Z",
     "shell.execute_reply.started": "2021-09-19T13:09:48.055354Z"
    },
    "papermill": {
     "duration": 0.046833,
     "end_time": "2021-09-19T13:17:26.971970",
     "exception": false,
     "start_time": "2021-09-19T13:17:26.925137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size, \n",
    "                 dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        \"\"\"\n",
    "        :param hidden_size: the hidden matrix for RNN\n",
    "        :param output_size: the size of the vocab of \n",
    "            lang to be translated to.\n",
    "        :param dropout_p: dropout probability\n",
    "        :param max_length: the maximum length of the sequence\n",
    "        \"\"\"\n",
    "        \n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        \n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        \n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        :param x: the input tensor for the decoder (used only for training)\n",
    "        :param hidden: the hidden context vectors\n",
    "        :param encoder_outputs: the encoder outputs for the sentence\n",
    "        \"\"\"\n",
    "        \n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        # shape (1, 1, batch_size * seq_len * embedding_size)\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # Concatenating the previous hidden and the encoder outputs\n",
    "        # Then calculating the `attention weights`\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)),\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        # Applying attention: multiplying the corresponding attention\n",
    "        # with the encoder output\n",
    "        attn_applied = torch.bmm(\n",
    "            attn_weights.unsqueeze(0),\n",
    "            encoder_outputs.unsqueeze(0)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Concatenating the ``Word to be predicted`` embedding\n",
    "        # with the ``attention applied`` encoder vectors\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        \n",
    "        output = F.relu(output)\n",
    "        \n",
    "        # at first, this hidden is the context vector from the encoder\n",
    "        # after that, we will pass this hidden, as the ``decoder hidden`` context vector\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        \n",
    "        # This output goes towards predicting the required translated word\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5c5cd",
   "metadata": {
    "papermill": {
     "duration": 0.030751,
     "end_time": "2021-09-19T13:17:27.037084",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.006333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a995bfe",
   "metadata": {
    "papermill": {
     "duration": 0.030816,
     "end_time": "2021-09-19T13:17:27.097979",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.067163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0cc183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.167926Z",
     "iopub.status.busy": "2021-09-19T13:17:27.167301Z",
     "iopub.status.idle": "2021-09-19T13:17:27.172193Z",
     "shell.execute_reply": "2021-09-19T13:17:27.171555Z",
     "shell.execute_reply.started": "2021-09-19T13:09:54.640143Z"
    },
    "papermill": {
     "duration": 0.044265,
     "end_time": "2021-09-19T13:17:27.172400",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.128135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    converts the words of a sentence to a list of indexes\n",
    "    \"\"\"\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    \"\"\"\n",
    "    converts the sentence to it's corresponding Tensor\n",
    "    \"\"\"\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    \"\"\"\n",
    "    transform the sentences in the pair\n",
    "    \n",
    "    e.g:\n",
    "        [\"I am cold.\", \"J'ai froid.\"] --> ([34, 88, 91], [22, 45, 97])\n",
    "    \"\"\"\n",
    "    \n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    output_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    \n",
    "    return (input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813acdab",
   "metadata": {
    "papermill": {
     "duration": 0.030529,
     "end_time": "2021-09-19T13:17:27.233864",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.203335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6201749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.315671Z",
     "iopub.status.busy": "2021-09-19T13:17:27.314571Z",
     "iopub.status.idle": "2021-09-19T13:17:27.317914Z",
     "shell.execute_reply": "2021-09-19T13:17:27.317304Z",
     "shell.execute_reply.started": "2021-09-19T13:09:55.943080Z"
    },
    "papermill": {
     "duration": 0.052396,
     "end_time": "2021-09-19T13:17:27.318059",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.265663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_force_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, \n",
    "          criterion, max_length=MAX_LENGTH):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param input_tensor: the input sequence\n",
    "    :param target_tensor: the target sequence\n",
    "    :param encoder: the Encoder\n",
    "    :param decoder: the Decoder\n",
    "    :param encoder_optimizer: the optimizer used for Encoder\n",
    "    :param decoder_optimizer: the optimizer used for Decoder\n",
    "    :param criterion: the loss function used\n",
    "    :param max_length: the max length of the sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden\n",
    "        )\n",
    "        \n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "        \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    \n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_force_ratio else False\n",
    "        \n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        # Feed the target as the next input\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        # Use own prediction as the next input\n",
    "        \n",
    "        for di in range(target_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            # topk : k largest\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            \n",
    "            decoder_input = topi.squeeze().detach() # detach from history as input\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            \n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "                \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce5eba7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.385153Z",
     "iopub.status.busy": "2021-09-19T13:17:27.384071Z",
     "iopub.status.idle": "2021-09-19T13:17:27.387371Z",
     "shell.execute_reply": "2021-09-19T13:17:27.386846Z",
     "shell.execute_reply.started": "2021-09-19T13:09:56.171275Z"
    },
    "papermill": {
     "duration": 0.03919,
     "end_time": "2021-09-19T13:17:27.387491",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.348301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  a helper function to print time elapsed and estimated time \n",
    "# remaining given the current time and progress %.\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9fb14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.455403Z",
     "iopub.status.busy": "2021-09-19T13:17:27.454166Z",
     "iopub.status.idle": "2021-09-19T13:17:27.457570Z",
     "shell.execute_reply": "2021-09-19T13:17:27.456946Z",
     "shell.execute_reply.started": "2021-09-19T13:09:56.391508Z"
    },
    "papermill": {
     "duration": 0.041971,
     "end_time": "2021-09-19T13:17:27.457731",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.415760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=100, plot_every=100, \n",
    "               learning_rate=0.01):\n",
    "    \"\"\"\n",
    "    :param encoder: the Encoder\n",
    "    :param decoder: the Decoder\n",
    "    :param n_iters: the number of epochs\n",
    "    :param print_every: print every 100th result\n",
    "    :param plot_every: plot every 100th result\n",
    "    :param learning_rate: the learning rate to be applied\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    \n",
    "    print_loss_total = 0 # Reset at every print_every\n",
    "    plot_loss_total = 0 # Reset at every plot_every\n",
    "    \n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                     for i in range(n_iters)]\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        \n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, \n",
    "                     encoder_optimizer, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            \n",
    "        \n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f626150",
   "metadata": {
    "papermill": {
     "duration": 0.028465,
     "end_time": "2021-09-19T13:17:27.515151",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.486686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc394308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.578698Z",
     "iopub.status.busy": "2021-09-19T13:17:27.577811Z",
     "iopub.status.idle": "2021-09-19T13:17:27.581297Z",
     "shell.execute_reply": "2021-09-19T13:17:27.580762Z",
     "shell.execute_reply.started": "2021-09-19T13:10:29.787818Z"
    },
    "papermill": {
     "duration": 0.038102,
     "end_time": "2021-09-19T13:17:27.581458",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.543356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    \n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58091e14",
   "metadata": {
    "papermill": {
     "duration": 0.027866,
     "end_time": "2021-09-19T13:17:27.636694",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.608828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "788e2cc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.705550Z",
     "iopub.status.busy": "2021-09-19T13:17:27.704409Z",
     "iopub.status.idle": "2021-09-19T13:17:27.707142Z",
     "shell.execute_reply": "2021-09-19T13:17:27.707649Z",
     "shell.execute_reply.started": "2021-09-19T13:12:14.810382Z"
    },
    "papermill": {
     "duration": 0.042301,
     "end_time": "2021-09-19T13:17:27.707788",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.665487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, \n",
    "             max_length=MAX_LENGTH):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param encoder: the Encoder\n",
    "    :param decoder: the Decoder\n",
    "    :param sentence: the input sentence\n",
    "    :param max_length: the max length of the sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, \n",
    "                                      device=device)\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            \n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], \n",
    "                                                     encoder_hidden)\n",
    "            \n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        \n",
    "        decoder_hidden = encoder_hidden\n",
    "        \n",
    "        decoded_words = []\n",
    "        \n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            \n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            \n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "                \n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81ccd0fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.771868Z",
     "iopub.status.busy": "2021-09-19T13:17:27.770950Z",
     "iopub.status.idle": "2021-09-19T13:17:27.774358Z",
     "shell.execute_reply": "2021-09-19T13:17:27.773825Z",
     "shell.execute_reply.started": "2021-09-19T13:12:17.208957Z"
    },
    "papermill": {
     "duration": 0.038657,
     "end_time": "2021-09-19T13:17:27.774482",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.735825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate Randomly\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    \n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        \n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5ff409d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:17:27.836964Z",
     "iopub.status.busy": "2021-09-19T13:17:27.836145Z",
     "iopub.status.idle": "2021-09-19T13:21:06.647110Z",
     "shell.execute_reply": "2021-09-19T13:21:06.646310Z",
     "shell.execute_reply.started": "2021-09-19T13:14:20.278082Z"
    },
    "papermill": {
     "duration": 218.843561,
     "end_time": "2021-09-19T13:21:06.647284",
     "exception": false,
     "start_time": "2021-09-19T13:17:27.803723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 21s (- 1m 10s) (5000 66%) 2.8458\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 7500, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b81a1f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:21:06.711064Z",
     "iopub.status.busy": "2021-09-19T13:21:06.709920Z",
     "iopub.status.idle": "2021-09-19T13:21:06.837032Z",
     "shell.execute_reply": "2021-09-19T13:21:06.837970Z",
     "shell.execute_reply.started": "2021-09-19T13:14:28.891813Z"
    },
    "papermill": {
     "duration": 0.161544,
     "end_time": "2021-09-19T13:21:06.838147",
     "exception": false,
     "start_time": "2021-09-19T13:21:06.676603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> c est un jeune adolescent impressionnable .\n",
      "= he s a young impressionable teenager .\n",
      "< he s a bit good . . <EOS>\n",
      "\n",
      "> elle est inquie te pour votre se curite .\n",
      "= she s worried about your safety .\n",
      "< she s very good for my . . <EOS>\n",
      "\n",
      "> je vais vraiment manquer a tom .\n",
      "= i m really going to miss tom .\n",
      "< i m going to to the . . <EOS>\n",
      "\n",
      "> elles sont dans le laboratoire de sciences .\n",
      "= they re in the science lab .\n",
      "< they are in the . <EOS>\n",
      "\n",
      "> je suis au lit .\n",
      "= i m in bed .\n",
      "< i m a . . . <EOS>\n",
      "\n",
      "> il est impitoyable .\n",
      "= he s ruthless .\n",
      "< he s in . <EOS>\n",
      "\n",
      "> elle vous attend chez nous .\n",
      "= she s waiting for you at home .\n",
      "< she is going to . . . <EOS>\n",
      "\n",
      "> vous e tes trop maigrichon .\n",
      "= you re too skinny .\n",
      "< you re very talented . <EOS>\n",
      "\n",
      "> vous n e tes pas ainsi d ordinaire .\n",
      "= you re not usually like this .\n",
      "< you re not a . . . <EOS>\n",
      "\n",
      "> je vais faire un feu .\n",
      "= i m going to build a fire .\n",
      "< i m going to . . . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a707092",
   "metadata": {
    "papermill": {
     "duration": 0.028619,
     "end_time": "2021-09-19T13:21:06.894592",
     "exception": false,
     "start_time": "2021-09-19T13:21:06.865973",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Visualising Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcee423a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:21:06.958235Z",
     "iopub.status.busy": "2021-09-19T13:21:06.957160Z",
     "iopub.status.idle": "2021-09-19T13:21:07.101941Z",
     "shell.execute_reply": "2021-09-19T13:21:07.100270Z",
     "shell.execute_reply.started": "2021-09-19T13:14:32.327735Z"
    },
    "papermill": {
     "duration": 0.178901,
     "end_time": "2021-09-19T13:21:07.102270",
     "exception": false,
     "start_time": "2021-09-19T13:21:06.923369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f33e34d7510>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words, attentions = evaluate(\n",
    "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
    "\n",
    "plt.matshow(attentions.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81edf9f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-19T13:21:07.194184Z",
     "iopub.status.busy": "2021-09-19T13:21:07.192928Z",
     "iopub.status.idle": "2021-09-19T13:21:08.211910Z",
     "shell.execute_reply": "2021-09-19T13:21:08.213603Z",
     "shell.execute_reply.started": "2021-09-19T13:16:23.118368Z"
    },
    "papermill": {
     "duration": 1.062018,
     "end_time": "2021-09-19T13:21:08.213977",
     "exception": false,
     "start_time": "2021-09-19T13:21:07.151959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = elle a cinq ans de moins que moi .\n",
      "output = she s going to as . . <EOS>\n",
      "input = elle est trop petit .\n",
      "output = she is very for . . <EOS>\n",
      "input = je ne crains pas de mourir .\n",
      "output = i m not going . . . <EOS>\n",
      "input = c est un jeune directeur plein de talent .\n",
      "output = he s a bit and a . . <EOS>\n"
     ]
    }
   ],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
    "\n",
    "evaluateAndShowAttention(\"elle est trop petit .\")\n",
    "\n",
    "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
    "\n",
    "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7a2280",
   "metadata": {
    "papermill": {
     "duration": 0.055434,
     "end_time": "2021-09-19T13:21:08.346821",
     "exception": false,
     "start_time": "2021-09-19T13:21:08.291387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 243.823465,
   "end_time": "2021-09-19T13:21:10.432630",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-19T13:17:06.609165",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
