{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "046b03d7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.026556,
     "end_time": "2021-10-31T21:29:02.248308",
     "exception": false,
     "start_time": "2021-10-31T21:29:02.221752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Neural Machine Translation by Jointly Learning to Align and Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f22ab40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:02.306575Z",
     "iopub.status.busy": "2021-10-31T21:29:02.304983Z",
     "iopub.status.idle": "2021-10-31T21:29:12.295450Z",
     "shell.execute_reply": "2021-10-31T21:29:12.294780Z",
     "shell.execute_reply.started": "2021-10-31T21:26:15.607225Z"
    },
    "papermill": {
     "duration": 10.019764,
     "end_time": "2021-10-31T21:29:12.295607",
     "exception": false,
     "start_time": "2021-10-31T21:29:02.275843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08961e7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:12.350830Z",
     "iopub.status.busy": "2021-10-31T21:29:12.350181Z",
     "iopub.status.idle": "2021-10-31T21:29:12.354548Z",
     "shell.execute_reply": "2021-10-31T21:29:12.354957Z",
     "shell.execute_reply.started": "2021-10-31T21:26:25.761471Z"
    },
    "papermill": {
     "duration": 0.033625,
     "end_time": "2021-10-31T21:29:12.355096",
     "exception": false,
     "start_time": "2021-10-31T21:29:12.321471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a9ab4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-27T19:17:28.970367Z",
     "iopub.status.busy": "2021-10-27T19:17:28.969619Z",
     "iopub.status.idle": "2021-10-27T19:17:28.974791Z",
     "shell.execute_reply": "2021-10-27T19:17:28.974023Z",
     "shell.execute_reply.started": "2021-10-27T19:17:28.9703Z"
    },
    "papermill": {
     "duration": 0.025211,
     "end_time": "2021-10-31T21:29:12.406144",
     "exception": false,
     "start_time": "2021-10-31T21:29:12.380933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebcb1ae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:12.460508Z",
     "iopub.status.busy": "2021-10-31T21:29:12.459722Z",
     "iopub.status.idle": "2021-10-31T21:29:30.115036Z",
     "shell.execute_reply": "2021-10-31T21:29:30.115477Z",
     "shell.execute_reply.started": "2021-10-31T21:26:25.770224Z"
    },
    "papermill": {
     "duration": 17.684125,
     "end_time": "2021-10-31T21:29:30.115648",
     "exception": false,
     "start_time": "2021-10-31T21:29:12.431523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (58.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting de-core-news-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.1.0/de_core_news_sm-3.1.0-py3-none-any.whl (18.8 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from de-core-news-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (21.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (58.0.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.62.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.10.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.19.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (3.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (4.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.2.0,>=3.1.0->de-core-news-sm==3.1.0) (2.0.1)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli \n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4264ef57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:30.180344Z",
     "iopub.status.busy": "2021-10-31T21:29:30.179509Z",
     "iopub.status.idle": "2021-10-31T21:29:32.791373Z",
     "shell.execute_reply": "2021-10-31T21:29:32.790831Z",
     "shell.execute_reply.started": "2021-10-31T21:26:42.530763Z"
    },
    "papermill": {
     "duration": 2.645922,
     "end_time": "2021-10-31T21:29:32.791509",
     "exception": false,
     "start_time": "2021-10-31T21:29:30.145587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating tokenizers\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10ca8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:32.856315Z",
     "iopub.status.busy": "2021-10-31T21:29:32.855447Z",
     "iopub.status.idle": "2021-10-31T21:29:32.857340Z",
     "shell.execute_reply": "2021-10-31T21:29:32.857823Z",
     "shell.execute_reply.started": "2021-10-31T21:26:45.350521Z"
    },
    "papermill": {
     "duration": 0.036424,
     "end_time": "2021-10-31T21:29:32.857976",
     "exception": false,
     "start_time": "2021-10-31T21:29:32.821552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens)\n",
    "    \n",
    "    :param text: the german sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "    \n",
    "    :param text: the english sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d035988",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:32.921510Z",
     "iopub.status.busy": "2021-10-31T21:29:32.920724Z",
     "iopub.status.idle": "2021-10-31T21:29:32.922625Z",
     "shell.execute_reply": "2021-10-31T21:29:32.923065Z",
     "shell.execute_reply.started": "2021-10-31T21:26:45.360272Z"
    },
    "papermill": {
     "duration": 0.036486,
     "end_time": "2021-10-31T21:29:32.923225",
     "exception": false,
     "start_time": "2021-10-31T21:29:32.886739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source is in German and Target is in English\n",
    "\n",
    "SRC = Field(tokenize = tokenize_de,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c6d21e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:32.985612Z",
     "iopub.status.busy": "2021-10-31T21:29:32.984813Z",
     "iopub.status.idle": "2021-10-31T21:29:39.310501Z",
     "shell.execute_reply": "2021-10-31T21:29:39.309957Z",
     "shell.execute_reply.started": "2021-10-31T21:26:45.371657Z"
    },
    "papermill": {
     "duration": 6.358281,
     "end_time": "2021-10-31T21:29:39.310639",
     "exception": false,
     "start_time": "2021-10-31T21:29:32.952358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 4.95MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.49MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.36MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and load the train, valid and test data\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'),\n",
    "    fields = (SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d76d491d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:39.385188Z",
     "iopub.status.busy": "2021-10-31T21:29:39.383482Z",
     "iopub.status.idle": "2021-10-31T21:29:39.387532Z",
     "shell.execute_reply": "2021-10-31T21:29:39.386829Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.378948Z"
    },
    "papermill": {
     "duration": 0.04395,
     "end_time": "2021-10-31T21:29:39.387665",
     "exception": false,
     "start_time": "2021-10-31T21:29:39.343715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n",
      "{'src': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"
     ]
    }
   ],
   "source": [
    "# Verifying\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "134b2bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:39.511666Z",
     "iopub.status.busy": "2021-10-31T21:29:39.490918Z",
     "iopub.status.idle": "2021-10-31T21:29:39.738970Z",
     "shell.execute_reply": "2021-10-31T21:29:39.738478Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.388249Z"
    },
    "papermill": {
     "duration": 0.318608,
     "end_time": "2021-10-31T21:29:39.739104",
     "exception": false,
     "start_time": "2021-10-31T21:29:39.420496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# building vocabulary\n",
    "# min_freq => min threshold to include the word in the vocab\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d2dab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:39.809866Z",
     "iopub.status.busy": "2021-10-31T21:29:39.809255Z",
     "iopub.status.idle": "2021-10-31T21:29:39.811740Z",
     "shell.execute_reply": "2021-10-31T21:29:39.812180Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.661748Z"
    },
    "papermill": {
     "duration": 0.039853,
     "end_time": "2021-10-31T21:29:39.812306",
     "exception": false,
     "start_time": "2021-10-31T21:29:39.772453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7853\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "# Unique Tokens\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac697b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-27T19:21:18.743179Z",
     "iopub.status.busy": "2021-10-27T19:21:18.742534Z",
     "iopub.status.idle": "2021-10-27T19:21:18.747143Z",
     "shell.execute_reply": "2021-10-27T19:21:18.746118Z",
     "shell.execute_reply.started": "2021-10-27T19:21:18.743132Z"
    },
    "papermill": {
     "duration": 0.032713,
     "end_time": "2021-10-31T21:29:39.878418",
     "exception": false,
     "start_time": "2021-10-31T21:29:39.845705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da688d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:39.951206Z",
     "iopub.status.busy": "2021-10-31T21:29:39.950485Z",
     "iopub.status.idle": "2021-10-31T21:29:39.953371Z",
     "shell.execute_reply": "2021-10-31T21:29:39.952931Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.667908Z"
    },
    "papermill": {
     "duration": 0.041321,
     "end_time": "2021-10-31T21:29:39.953482",
     "exception": false,
     "start_time": "2021-10-31T21:29:39.912161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882705a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:40.023332Z",
     "iopub.status.busy": "2021-10-31T21:29:40.022530Z",
     "iopub.status.idle": "2021-10-31T21:29:40.027021Z",
     "shell.execute_reply": "2021-10-31T21:29:40.027431Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.682369Z"
    },
    "papermill": {
     "duration": 0.040704,
     "end_time": "2021-10-31T21:29:40.027566",
     "exception": false,
     "start_time": "2021-10-31T21:29:39.986862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f46c4",
   "metadata": {
    "papermill": {
     "duration": 0.032351,
     "end_time": "2021-10-31T21:29:40.094207",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.061856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805bcd10",
   "metadata": {
    "papermill": {
     "duration": 0.032981,
     "end_time": "2021-10-31T21:29:40.160566",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.127585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c68c0c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:40.236949Z",
     "iopub.status.busy": "2021-10-31T21:29:40.236141Z",
     "iopub.status.idle": "2021-10-31T21:29:40.238715Z",
     "shell.execute_reply": "2021-10-31T21:29:40.238233Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.689633Z"
    },
    "papermill": {
     "duration": 0.045247,
     "end_time": "2021-10-31T21:29:40.238832",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.193585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        \"\"\"\n",
    "        :param input_dim: It is the size/dimensionality of the one-hot vectors that will be input to the encoder. \n",
    "                        This is equal to the input (source) vocabulary size.\n",
    "        :param emb_dim: It is the dimensionality of the embedding layer. \n",
    "                        This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "        :param enc_hid_dim: It is the dimensionality of the hidden state of the encoder\n",
    "        :param dec_hid_dim: It is the dimensionality of the hidden state of the decoder\n",
    "                        Actually, we will convert the output vectors from the GRU, to a \n",
    "                        Linear Layer, so that its dimension matches with that of the decoder\n",
    "        :param dropout: It is the amount of dropout to use. \n",
    "                        This is a regularization parameter to prevent overfitting.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        # src.shape => (src_len, batch_size)\n",
    "\n",
    "        # example, src will be like:\n",
    "\n",
    "            # | I ,     Good,       How,    ... |\n",
    "            # | have,   morning,    are,    ... |\n",
    "            # | a,      <eos>,      you,    ... |\n",
    "            # | dog,    <pad>,      <eos>,  ... |\n",
    "            # | <eos>,  <pad>,      <pad>,  ... |\n",
    "\n",
    "            # In this number of rows = src_len or max_len\n",
    "            # and number of columns = batch_size\n",
    "            \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded.shape => (src_len, batch_size, emb_dim)\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedded) # no cell state!\n",
    "        \n",
    "        # outputs.shape => (src_len, batch_size, enc_hid_dim * n_directions)\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, enc_hid_dim)\n",
    "        \n",
    "        # here, n_directions = 2\n",
    "        # hidden is stacked as [forward1, backward1, forward2, backward2, ..., forward_batch_size, backward_batch_size]\n",
    "        # outputs are always from the last layer\n",
    "        \n",
    "        # hidden[-2, :, :] --> last of the forwards RNN\n",
    "        # hidden[-1, :, :] --> last of the backwards RNN\n",
    "        \n",
    "        # initial decoder hidden = final hidden state of the forwards and backwards FOR ALL BATCHES\n",
    "        # encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(\n",
    "            self.fc(\n",
    "                torch.cat((hidden[-2, :, :], hidden[-1, :, :]),\n",
    "                dim = 1)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # outputs.shape => (src_len, batch_size, enc_hid_dim * 2)\n",
    "        # hidden.shape => (batch_size, dec_hid_dim)\n",
    "        \n",
    "        return outputs, hidden\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9685e1a",
   "metadata": {
    "papermill": {
     "duration": 0.033614,
     "end_time": "2021-10-31T21:29:40.306801",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.273187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2001ca8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:40.384021Z",
     "iopub.status.busy": "2021-10-31T21:29:40.383409Z",
     "iopub.status.idle": "2021-10-31T21:29:40.386961Z",
     "shell.execute_reply": "2021-10-31T21:29:40.386460Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.705336Z"
    },
    "papermill": {
     "duration": 0.046507,
     "end_time": "2021-10-31T21:29:40.387071",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.340564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        \"\"\"\n",
    "        :param enc_hid_dim: It is the dimensionality of the hidden state of the encoder\n",
    "        :param dec_hid_dim: It is the dimensionality of the hidden state of the decoder\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        \n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        # hidden.shape => (batch_size, dec_hid_dim)\n",
    "        # encoder_outputs.shape => (src_len, batch_size, enc_hid_dim * 2)\n",
    "        # 2 because n_directions = 2\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        # repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        # hidden.shape => (batch_size, src_len, dec_hid_dim)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs.shape => (batch_size, src_len, enc_hid_dim * 2)\n",
    "        \n",
    "        energy = torch.tanh(\n",
    "            self.attn(\n",
    "                torch.cat((hidden, encoder_outputs), dim = 2)\n",
    "            )\n",
    "        )\n",
    "        # energy.shape => (batch_size, src_len, dec_hid_dim)\n",
    "        \n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        # attention.shape => (batch_size, src_len)\n",
    "        \n",
    "        return F.softmax(attention, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9958aa2",
   "metadata": {
    "papermill": {
     "duration": 0.032728,
     "end_time": "2021-10-31T21:29:40.453302",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.420574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "508faf92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:40.532419Z",
     "iopub.status.busy": "2021-10-31T21:29:40.531628Z",
     "iopub.status.idle": "2021-10-31T21:29:40.534285Z",
     "shell.execute_reply": "2021-10-31T21:29:40.533817Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.716765Z"
    },
    "papermill": {
     "duration": 0.047975,
     "end_time": "2021-10-31T21:29:40.534401",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.486426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        \"\"\"\n",
    "        :param output_dim: It is the size/dimensionality of the one-hot vectors that will be the output of the decoder.\n",
    "                        This is equal to the output (target) vocabulary size.\n",
    "        :param emb_dim: It is the dimensionality of the embedding layer. \n",
    "                        This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "        :param enc_hid_dim: It is the dimensionality of the hidden state of the encoder\n",
    "        :param dec_hid_dim: It is the dimensionality of the hidden state of the decoder (GRU)\n",
    "        :param dropout: It is the amount of dropout to use. \n",
    "                        This is a regularization parameter to prevent overfitting.\n",
    "        :param attention: the attention vector obtained from the Attention Mechanism.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        \n",
    "        # input.shape => (batch_size,)\n",
    "        # hidden.shape => (batch_size, dec_hid_dim)\n",
    "        # encoder_outputs.shape => (src_len, batch_size, enc_hid_dim * 2)\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        # input.shape => (1, batch_size)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded.shape => (1, batch_size, emb_dim)\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        # a.shape => (batch_size, src_len)\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        # a.shape => (batch_size, 1, src_len)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs.shape => (batch_size, src_len, enc_hid_dim * 2)\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        # a1 : b X n X m\n",
    "        # a2 : b X m X p\n",
    "        # bmm(a1, a2) --> b X n X p\n",
    "        \n",
    "        # weighted.shape => (batch_size, 1, enc_hid_dim * 2)\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted.shape => (1, batch_size, enc_hid_dim * 2)\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        # rnn.shape => (1, batch_size, (enc_hid_dim * 2) + emb_dim)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        # output.shape => (seq_len, batch_size, dec_hid_dim * n_directions)\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, dec_hid_dim)\n",
    "        \n",
    "        # as seq_len = 1\n",
    "        # n_layers and n_directions = 1 in this decoder\n",
    "        \n",
    "        # output.shape => (1, batch_size, dec_hid_dim)\n",
    "        # hidden.shape => (1, batch_size, dec_hid_dim)\n",
    "        \n",
    "        # implying that output == hidden\n",
    "        \n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        # embedded.shape => (batch_size, emb_dim)\n",
    "        \n",
    "        output = output.squeeze(0)\n",
    "        # output.shape => (batch_size, dec_hid_dim)\n",
    "        \n",
    "        weighted = weighted.squeeze(0)\n",
    "        # weighted.shape => (batch_size, enc_hid_dim * 2)\n",
    "        \n",
    "        prediction = self.fc_out(\n",
    "            torch.cat((output, weighted, embedded), dim = 1)\n",
    "        )\n",
    "        # prediction.shape => (batch_size, output_dim)\n",
    "        \n",
    "        return prediction, hidden.squeeze(0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e43544",
   "metadata": {
    "papermill": {
     "duration": 0.033284,
     "end_time": "2021-10-31T21:29:40.600113",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.566829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "869d104c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:40.725407Z",
     "iopub.status.busy": "2021-10-31T21:29:40.724594Z",
     "iopub.status.idle": "2021-10-31T21:29:40.727299Z",
     "shell.execute_reply": "2021-10-31T21:29:40.726794Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.736794Z"
    },
    "papermill": {
     "duration": 0.044702,
     "end_time": "2021-10-31T21:29:40.727407",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.682705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \"\"\"\n",
    "        :param src: the source sentence sequence\n",
    "                    src.shape => (src_len, batch_size)\n",
    "        :param trg: the target sentence sequence\n",
    "                    trg.shape => (trg_len, batch_size)\n",
    "        :param teacher_forcing_ratio: the ratio, used for training. It tells \n",
    "                    by how much probability, we should use the decoded token or\n",
    "                    the original token for training\n",
    "                    e.g. if teacher_forcing_ratio is 0.75, \n",
    "                    we use ground-truth inputs 75% of the time.\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # encoder_outputs is all hidden states of the input sentence, forwards and backwards\n",
    "        # hidden is the final forward and backward hidden states, passes through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        \n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            # receive output tensor (preictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            \n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            \n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c7a5a",
   "metadata": {
    "papermill": {
     "duration": 0.032822,
     "end_time": "2021-10-31T21:29:40.792788",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.759966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f276d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T20:27:48.179945Z",
     "iopub.status.busy": "2021-10-31T20:27:48.179515Z",
     "iopub.status.idle": "2021-10-31T20:27:48.183544Z",
     "shell.execute_reply": "2021-10-31T20:27:48.182963Z",
     "shell.execute_reply.started": "2021-10-31T20:27:48.179913Z"
    },
    "papermill": {
     "duration": 0.032639,
     "end_time": "2021-10-31T21:29:40.858649",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.826010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Init the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5802a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:40.932917Z",
     "iopub.status.busy": "2021-10-31T21:29:40.932275Z",
     "iopub.status.idle": "2021-10-31T21:29:49.078497Z",
     "shell.execute_reply": "2021-10-31T21:29:49.077911Z",
     "shell.execute_reply.started": "2021-10-31T21:26:51.749552Z"
    },
    "papermill": {
     "duration": 8.187222,
     "end_time": "2021-10-31T21:29:49.078655",
     "exception": false,
     "start_time": "2021-10-31T21:29:40.891433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "ENC_HID_DIM = 512\n",
    "DEC_HID_DIM = 512\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7ee8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T20:29:04.604330Z",
     "iopub.status.busy": "2021-10-31T20:29:04.603690Z",
     "iopub.status.idle": "2021-10-31T20:29:04.607923Z",
     "shell.execute_reply": "2021-10-31T20:29:04.607237Z",
     "shell.execute_reply.started": "2021-10-31T20:29:04.604283Z"
    },
    "papermill": {
     "duration": 0.03465,
     "end_time": "2021-10-31T21:29:49.151697",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.117047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We will initialize all biases to zero and all weights from $\\mathcal{N}(0, 0.01)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3302fa1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:49.224904Z",
     "iopub.status.busy": "2021-10-31T21:29:49.224142Z",
     "iopub.status.idle": "2021-10-31T21:29:49.236812Z",
     "shell.execute_reply": "2021-10-31T21:29:49.237271Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.046434Z"
    },
    "papermill": {
     "duration": 0.052181,
     "end_time": "2021-10-31T21:29:49.237425",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.185244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "        initializes the weights of the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5acc57dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:49.312440Z",
     "iopub.status.busy": "2021-10-31T21:29:49.311724Z",
     "iopub.status.idle": "2021-10-31T21:29:49.314553Z",
     "shell.execute_reply": "2021-10-31T21:29:49.315020Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.065310Z"
    },
    "papermill": {
     "duration": 0.042505,
     "end_time": "2021-10-31T21:29:49.315168",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.272663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 20,518,405 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f9e83af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:49.390869Z",
     "iopub.status.busy": "2021-10-31T21:29:49.390015Z",
     "iopub.status.idle": "2021-10-31T21:29:49.391808Z",
     "shell.execute_reply": "2021-10-31T21:29:49.392279Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.074447Z"
    },
    "papermill": {
     "duration": 0.042445,
     "end_time": "2021-10-31T21:29:49.392407",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.349962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf6d1eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:49.470845Z",
     "iopub.status.busy": "2021-10-31T21:29:49.469689Z",
     "iopub.status.idle": "2021-10-31T21:29:49.474773Z",
     "shell.execute_reply": "2021-10-31T21:29:49.475585Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.081059Z"
    },
    "papermill": {
     "duration": 0.048522,
     "end_time": "2021-10-31T21:29:49.475764",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.427242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "# NOTE: Our loss function calculates the average loss per token, \n",
    "# however by passing the index of the <pad> token as the ignore_index argument \n",
    "# we ignore the loss whenever the target token is a padding token.\n",
    "\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee1804",
   "metadata": {
    "papermill": {
     "duration": 0.073966,
     "end_time": "2021-10-31T21:29:49.615637",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.541671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da055b15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:49.742320Z",
     "iopub.status.busy": "2021-10-31T21:29:49.741438Z",
     "iopub.status.idle": "2021-10-31T21:29:49.745178Z",
     "shell.execute_reply": "2021-10-31T21:29:49.745567Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.091000Z"
    },
    "papermill": {
     "duration": 0.068393,
     "end_time": "2021-10-31T21:29:49.745712",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.677319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        # trg.shape => (trg_len, batch_size)\n",
    "        # output.shape => (trg_len, batch_size, output_dim)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        \n",
    "        # We have removed the <sos> token\n",
    "        # trg.shape => ((trg_len - 1) * batch_size)\n",
    "        # output.shape => ((trg_len - 1) * batch_size, output_dim)\n",
    "        \n",
    "        # NOTE:  the loss function only works on 2d inputs with 1d targets\n",
    "        # we need to flatten each of them with .view\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0f5d4",
   "metadata": {
    "papermill": {
     "duration": 0.054894,
     "end_time": "2021-10-31T21:29:49.855486",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.800592",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "246fa476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:49.975251Z",
     "iopub.status.busy": "2021-10-31T21:29:49.974426Z",
     "iopub.status.idle": "2021-10-31T21:29:49.979267Z",
     "shell.execute_reply": "2021-10-31T21:29:49.980196Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.103953Z"
    },
    "papermill": {
     "duration": 0.06981,
     "end_time": "2021-10-31T21:29:49.980388",
     "exception": false,
     "start_time": "2021-10-31T21:29:49.910578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            # trg.shape => (trg_len, batch_size)\n",
    "            # output.shape => (trg_len, batch_size, output_dim)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            # We have removed the <sos> token\n",
    "            # trg.shape => ((trg_len - 1) * batch_size)\n",
    "            # output.shape => ((trg_len - 1) * batch_size, output_dim)\n",
    "\n",
    "            # NOTE:  the loss function only works on 2d inputs with 1d targets\n",
    "            # we need to flatten each of them with .view\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a85d7266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:50.101145Z",
     "iopub.status.busy": "2021-10-31T21:29:50.100150Z",
     "iopub.status.idle": "2021-10-31T21:29:50.102165Z",
     "shell.execute_reply": "2021-10-31T21:29:50.102625Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.114618Z"
    },
    "papermill": {
     "duration": 0.066074,
     "end_time": "2021-10-31T21:29:50.102796",
     "exception": false,
     "start_time": "2021-10-31T21:29:50.036722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68c233",
   "metadata": {
    "papermill": {
     "duration": 0.035609,
     "end_time": "2021-10-31T21:29:50.177674",
     "exception": false,
     "start_time": "2021-10-31T21:29:50.142065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86234e7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:29:50.300053Z",
     "iopub.status.busy": "2021-10-31T21:29:50.284993Z",
     "iopub.status.idle": "2021-10-31T21:40:54.127644Z",
     "shell.execute_reply": "2021-10-31T21:40:54.128091Z",
     "shell.execute_reply.started": "2021-10-31T21:27:00.126702Z"
    },
    "papermill": {
     "duration": 663.916937,
     "end_time": "2021-10-31T21:40:54.128245",
     "exception": false,
     "start_time": "2021-10-31T21:29:50.211308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 1m 7s\n",
      "\tTrain Loss: 5.016 | Train PPL: 150.795\n",
      "\t Val. Loss: 4.860 |  Val. PPL: 129.036\n",
      "Epoch: 02 | Time: 1m 6s\n",
      "\tTrain Loss: 4.163 | Train PPL:  64.235\n",
      "\t Val. Loss: 4.703 |  Val. PPL: 110.264\n",
      "Epoch: 03 | Time: 1m 5s\n",
      "\tTrain Loss: 3.536 | Train PPL:  34.341\n",
      "\t Val. Loss: 3.815 |  Val. PPL:  45.398\n",
      "Epoch: 04 | Time: 1m 6s\n",
      "\tTrain Loss: 2.967 | Train PPL:  19.425\n",
      "\t Val. Loss: 3.439 |  Val. PPL:  31.157\n",
      "Epoch: 05 | Time: 1m 6s\n",
      "\tTrain Loss: 2.563 | Train PPL:  12.971\n",
      "\t Val. Loss: 3.287 |  Val. PPL:  26.758\n",
      "Epoch: 06 | Time: 1m 6s\n",
      "\tTrain Loss: 2.265 | Train PPL:   9.627\n",
      "\t Val. Loss: 3.219 |  Val. PPL:  25.012\n",
      "Epoch: 07 | Time: 1m 5s\n",
      "\tTrain Loss: 2.020 | Train PPL:   7.535\n",
      "\t Val. Loss: 3.159 |  Val. PPL:  23.557\n",
      "Epoch: 08 | Time: 1m 5s\n",
      "\tTrain Loss: 1.793 | Train PPL:   6.007\n",
      "\t Val. Loss: 3.188 |  Val. PPL:  24.251\n",
      "Epoch: 09 | Time: 1m 6s\n",
      "\tTrain Loss: 1.620 | Train PPL:   5.054\n",
      "\t Val. Loss: 3.248 |  Val. PPL:  25.726\n",
      "Epoch: 10 | Time: 1m 5s\n",
      "\tTrain Loss: 1.509 | Train PPL:   4.523\n",
      "\t Val. Loss: 3.319 |  Val. PPL:  27.645\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ee1d667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-31T21:40:54.206044Z",
     "iopub.status.busy": "2021-10-31T21:40:54.204974Z",
     "iopub.status.idle": "2021-10-31T21:40:54.978010Z",
     "shell.execute_reply": "2021-10-31T21:40:54.979389Z",
     "shell.execute_reply.started": "2021-10-31T21:28:07.472851Z"
    },
    "papermill": {
     "duration": 0.815682,
     "end_time": "2021-10-31T21:40:54.979748",
     "exception": false,
     "start_time": "2021-10-31T21:40:54.164066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.135 | Test PPL:  22.992 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut3-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02743b",
   "metadata": {
    "papermill": {
     "duration": 0.075884,
     "end_time": "2021-10-31T21:40:55.133945",
     "exception": false,
     "start_time": "2021-10-31T21:40:55.058061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 723.689875,
   "end_time": "2021-10-31T21:40:58.321838",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-31T21:28:54.631963",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
