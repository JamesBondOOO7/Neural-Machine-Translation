{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "frank-colony",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:19.990923Z",
     "iopub.status.busy": "2021-06-23T08:10:19.990267Z",
     "iopub.status.idle": "2021-06-23T08:10:24.090162Z",
     "shell.execute_reply": "2021-06-23T08:10:24.089607Z",
     "shell.execute_reply.started": "2021-06-23T08:05:56.042223Z"
    },
    "papermill": {
     "duration": 4.128148,
     "end_time": "2021-06-23T08:10:24.090301",
     "exception": false,
     "start_time": "2021-06-23T08:10:19.962153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic utilities needed in the code\n",
    "\n",
    "import torch\n",
    "import spacy\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    \"\"\"\n",
    "    This function translates the input german sentence to the english sentence.\n",
    "    German sentence --> German Vector --> Encoder --> context vector --> Decoder --> English Vector --> English Sentence\n",
    "\n",
    "    :param model: the sequence-to-sequnce model\n",
    "    :param sentence: the input \"german\" sentence\n",
    "    :param german: the german Field object\n",
    "    :param english : the english Field object\n",
    "    :param device: cuda / cpu\n",
    "    :param max_length : maximum length of the translated sentence\n",
    "    \"\"\"\n",
    "\n",
    "    spacy_german = spacy.load(\"de\")\n",
    "\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_german(sentence)]\n",
    "\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # insert the start and end sequence\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    text_to_indicies = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # (N, ) --> (1 X N)\n",
    "    sentence_tensor = torch.LongTensor(text_to_indicies).unsqueeze(0).to(device)\n",
    "\n",
    "    # Retrieve the hidden_state and cell_state from the encoder\n",
    "    with torch.no_grad():\n",
    "        hidden_state, cell_state = model.Encoder_LSTM(sentence_tensor)\n",
    "\n",
    "    # start the decoding part using start sequence and the (hidden_state, cell_state)\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden_state, cell_state = model.Decoder_LSTM(previous_word, hidden_state, cell_state)\n",
    "\n",
    "            # shape received : 1 X 1 X |Eng_Vocab|; squeeze it\n",
    "            # output = output.squeeze(0)\n",
    "\n",
    "            best_guess = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        # Model stops predicting if it predicts <eos> token (index)\n",
    "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    # We have the indicies of the translated sentence in english\n",
    "    # Now, we will predict the sentence\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    \"\"\"\n",
    "    *** reference : https://www.youtube.com/watch?v=DejHQYAGb7Q ***\n",
    "    :param data: the batch containing german and english sentences\n",
    "    :param model: the model\n",
    "    :param german: the german Field object\n",
    "    :param english: the english Field object\n",
    "    :param device: cuda / cpu\n",
    "    \"\"\"\n",
    "\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        ger_sent = vars(example)[\"ger_sent\"]\n",
    "        eng_sent = vars(example)[\"eng_sent\"]\n",
    "        \n",
    "        prediction = translate_sentence(model, ger_sent, german, english, device)\n",
    "\n",
    "        # remove the <eos> token from the end\n",
    "        prediction = prediction[:-1]\n",
    "\n",
    "        targets.append([eng_sent])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-maple",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:24.174768Z",
     "iopub.status.busy": "2021-06-23T08:10:24.174071Z",
     "iopub.status.idle": "2021-06-23T08:10:29.773866Z",
     "shell.execute_reply": "2021-06-23T08:10:29.774456Z",
     "shell.execute_reply.started": "2021-06-23T08:06:00.964794Z"
    },
    "papermill": {
     "duration": 5.673889,
     "end_time": "2021-06-23T08:10:29.774659",
     "exception": false,
     "start_time": "2021-06-23T08:10:24.100770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (Encoder_LSTM): Encoder(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(5000, 300)\n",
      "    (rnn): LSTM(300, 1024, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  )\n",
      "  (Decoder_LSTM): Decoder(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(4500, 300)\n",
      "    (rnn): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "    (fc): Linear(in_features=1024, out_features=4500, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "# ---------------------------- ENCODER ----------------------------\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, drop_prob):\n",
    "        \"\"\"\n",
    "        :param input_size: the size of the input sequence\n",
    "        :param embedding_size: the embedding dimension\n",
    "        :param hidden_size: the hidden dimension used in the LSTM model\n",
    "        :param num_layers: number of layers in the LSTM model\n",
    "        :param drop_prob: the probability of dropout\n",
    "        \"\"\"\n",
    "\n",
    "        # self.param_dict = {\n",
    "        #     'input_size' : input_size,\n",
    "        #     'embedding_size' : embedding_size,\n",
    "        #     'hidden_size' : hidden_size,\n",
    "        #     'num_layers' : num_layers,\n",
    "        #     'drop_prob' : drop_prob\n",
    "        # }\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)  # for Regularization\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        \n",
    "        # the rnn cell\n",
    "        self.rnn = nn.LSTM(input_size = embedding_size,\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_layers = num_layers,\n",
    "                        dropout=drop_prob,\n",
    "                        batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: the vector form of the sentence \n",
    "                  (containing the indicies mapped in the vocab)\n",
    "        \"\"\"\n",
    "\n",
    "        # pass the data\n",
    "        # N X T --> N X T X D\n",
    "        x = self.dropout(self.embedding(x))\n",
    "\n",
    "        output, (hidden_state, cell_state) = self.rnn(x)\n",
    "\n",
    "        # return the context vectors\n",
    "        # their shape : L X N X H (num_layers X batch_size X hidden_size)\n",
    "        return hidden_state, cell_state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- DECODER ----------------------------\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, num_layers, drop_prob, output_size):\n",
    "        \"\"\"\n",
    "        :param input_size: the size of the input sequence\n",
    "        :param embedding_size: the embedding dimension\n",
    "        :param hidden_size: the hidden dimension used in the LSTM model\n",
    "        :param num_layers: number of layers in the LSTM model\n",
    "        :param drop_prob: the probability of dropout\n",
    "        :param output_size: the output size of the linear layer after the decoding\n",
    "        \"\"\"\n",
    "\n",
    "        # self.param_dict = {\n",
    "        #     'input_size' : input_size,\n",
    "        #     'embedding_size' : embedding_size,\n",
    "        #     'hidden_size' : hidden_size,\n",
    "        #     'num_layers' : num_layers,\n",
    "        #     'drop_prob' : drop_prob,\n",
    "        #     'output_size' : output_size\n",
    "        # }\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(drop_prob)  # for Regularization\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=embedding_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            dropout=drop_prob,\n",
    "                            # batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "\n",
    "        # unsqueeze x\n",
    "        # shape becomes : 1 X N\n",
    "        x = x.unsqueeze(0)\n",
    "\n",
    "        # 1 X N --> 1 X N X D\n",
    "        x = self.dropout(self.embedding(x))\n",
    "\n",
    "        # shape of outputs : 1 X N X H (1 X batch_size X Hidden_size)\n",
    "        # shape of hidden and cell states : L X N X H\n",
    "        outputs, (hidden_state, cell_state) = self.rnn(x, (hidden_state, cell_state))\n",
    "\n",
    "        # 1 X N X H --> 1 X N X output_size\n",
    "        predictions = self.fc(outputs)\n",
    "\n",
    "        # 1 X N X output_size --> N X output_size\n",
    "        predictions = predictions.squeeze(0)\n",
    "\n",
    "        return predictions, hidden_state, cell_state\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------- SEQUENCE-TO-SEQUENCE ----------------------------\n",
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "        \"\"\"\n",
    "        :param Encoder_LSTM: the encoder part for the Seq2Seq model\n",
    "        :param Decoder_LSTM: the decoder part for the Seq2Seq model\n",
    "        \"\"\"\n",
    "\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.Encoder_LSTM = Encoder_LSTM\n",
    "        self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "    def forward(self, source, target, eng_vocab_size, tfr=0.5):\n",
    "        \"\"\"\n",
    "        :param source: padded sentences in German\n",
    "                       shape : [(sentence length German + some padding), #Sentences]\n",
    "        :param target: padded sentences in English\n",
    "                       shape : [(sentence length English + some padding), #Sentences]\n",
    "        :param eng_vocab_size : size of the english vocab\n",
    "        :param tfr: teach force ratio\n",
    "        \"\"\"\n",
    "\n",
    "        # # Convert it into Batch Size X Sequence Length\n",
    "        # target = target.permute(1, 0)\n",
    "\n",
    "        batch_size = source.shape[0]\n",
    "        target_len = target.shape[0]\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, eng_vocab_size).to(device)\n",
    "\n",
    "        # retaining the context vector from the encoder\n",
    "        hidden_state, cell_state = self.Encoder_LSTM(source)\n",
    "\n",
    "        x = target[0]\n",
    "\n",
    "        for i in range(1, target_len):\n",
    "\n",
    "            # output : batch_size X |Eng_Vocab_Size|\n",
    "            output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
    "\n",
    "            outputs[i] = output\n",
    "\n",
    "            best_guess = output.argmax(1)  # the most suitable word embedding\n",
    "\n",
    "            # Teach force ratio\n",
    "            # Either pass the next correct word from the dataset\n",
    "            # or use the predicted word\n",
    "            x = target[i] if random.random() < tfr else best_guess\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # ..................... Some testing code .....................\n",
    "\n",
    "    # for encoder\n",
    "    input_size_encoder = 5000  # vocab size\n",
    "    encoder_embedding_size = 300\n",
    "    hidden_size = 1024\n",
    "    num_layers = 2\n",
    "    encoder_dropout = float(0.5)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    encoder_lstm = Encoder(input_size_encoder, encoder_embedding_size, \n",
    "                            hidden_size, num_layers, encoder_dropout).to(device)\n",
    "\n",
    "    # print(encoder_lstm)\n",
    "\n",
    "    # for decoder\n",
    "    input_size_decoder = 4500\n",
    "    decoder_embedding_size = 300\n",
    "    hidden_size = 1024\n",
    "    num_layers = 2\n",
    "    decoder_dropout = float(0.5)\n",
    "    output_size = 4500\n",
    "    \n",
    "    decoder_lstm = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, \n",
    "                            num_layers, decoder_dropout, output_size).to(device)\n",
    "\n",
    "    # print(decoder_lstm)\n",
    "\n",
    "    model = Seq2Seq(encoder_lstm, decoder_lstm)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "personalized-tribune",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:29.806362Z",
     "iopub.status.busy": "2021-06-23T08:10:29.805154Z",
     "iopub.status.idle": "2021-06-23T08:10:29.807795Z",
     "shell.execute_reply": "2021-06-23T08:10:29.807385Z",
     "shell.execute_reply.started": "2021-06-23T08:06:07.726156Z"
    },
    "papermill": {
     "duration": 0.021835,
     "end_time": "2021-06-23T08:10:29.807901",
     "exception": false,
     "start_time": "2021-06-23T08:10:29.786066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def testing_Iterators(train_iterator, test_iterator, GERMAN_VOCAB, ENGLISH_VOCAB):\n",
    "    \"\"\"\n",
    "    This function just prints the batches\n",
    "\n",
    "    :param train_iterator: iterator for training\n",
    "    :param test_iterator: iterator for testing\n",
    "    :param GERMAN_VOCAB: the German vocab\n",
    "    :param ENGLISH_VOCAB: the English vocab\n",
    "    \n",
    "    \"\"\"\n",
    "    for data in train_iterator:\n",
    "        # print(f\"Length : {data.ger_sent.shape}\")  # \"German :\", *data.ger_sent, \n",
    "        # print(f\"Length : {data.eng_sent.shape}\")  # \"English :\", *data.eng_sent, \n",
    "        \n",
    "        print(\"-------------- GERMAN SENTENCES ------------\")\n",
    "        print()\n",
    "        temp = data.ger_sent.permute(1, 0)\n",
    "        for ele in temp:\n",
    "            for num in ele:\n",
    "                print(GERMAN_VOCAB.itos[num.item()], end=\" \")\n",
    "\n",
    "            print()\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(\"-------------- ENGLISH SENTENCES ------------\")\n",
    "        print()\n",
    "        temp = data.eng_sent.permute(1, 0)\n",
    "        for ele in temp:\n",
    "            for num in ele:\n",
    "                print(ENGLISH_VOCAB.itos[num.item()], end=\" \")\n",
    "\n",
    "            print()\n",
    "\n",
    "        print()\n",
    "        break\n",
    "\n",
    "    for data in test_iterator:\n",
    "        # print(f\"Length : {data.ger_sent.shape}\")  # \"German :\", *data.ger_sent, \n",
    "        # print(f\"Length : {data.eng_sent.shape}\")  # \"English :\", *data.eng_sent, \n",
    "        \n",
    "        print(\"-------------- GERMAN SENTENCES ------------\")\n",
    "        print()\n",
    "        temp = data.ger_sent.permute(1, 0)\n",
    "        for ele in temp:\n",
    "            for num in ele:\n",
    "                print(GERMAN_VOCAB.itos[num.item()], end=\" \")\n",
    "\n",
    "            print()\n",
    "\n",
    "        print()\n",
    "\n",
    "        print(\"-------------- ENGLISH SENTENCES ------------\")\n",
    "        print()\n",
    "        temp = data.eng_sent.permute(1, 0)\n",
    "        for ele in temp:\n",
    "            for num in ele:\n",
    "                print(ENGLISH_VOCAB.itos[num.item()], end=\" \")\n",
    "\n",
    "            print()\n",
    "\n",
    "        print()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "useful-concept",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:29.832134Z",
     "iopub.status.busy": "2021-06-23T08:10:29.831456Z",
     "iopub.status.idle": "2021-06-23T08:10:29.834147Z",
     "shell.execute_reply": "2021-06-23T08:10:29.833760Z",
     "shell.execute_reply.started": "2021-06-23T08:06:22.278682Z"
    },
    "papermill": {
     "duration": 0.016139,
     "end_time": "2021-06-23T08:10:29.834247",
     "exception": false,
     "start_time": "2021-06-23T08:10:29.818108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# declare constants here...\n",
    "learning_rate = 0.003\n",
    "epochs = 100\n",
    "train_batch_size = 256\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "upper-mattress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:29.865127Z",
     "iopub.status.busy": "2021-06-23T08:10:29.864330Z",
     "iopub.status.idle": "2021-06-23T08:10:29.866894Z",
     "shell.execute_reply": "2021-06-23T08:10:29.866507Z",
     "shell.execute_reply.started": "2021-06-23T08:06:26.405604Z"
    },
    "papermill": {
     "duration": 0.022534,
     "end_time": "2021-06-23T08:10:29.866992",
     "exception": false,
     "start_time": "2021-06-23T08:10:29.844458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(data_loader, model, optimizer, criterion, english_vocab_size, device):\n",
    "    \"\"\"\n",
    "    This is the main training function that trains the model and\n",
    "    returns training loss\n",
    "\n",
    "    :param data_loader: this is the torch data loader\n",
    "    :param model: model (encoder - decoder model)\n",
    "    :param optimizer: torch optimizer, e.g. adam, sgd, etc.\n",
    "    :param criterion: loss function\n",
    "    :param english_vocab_size: size of the english vocabulary\n",
    "    :param device: this can be \"cuda\" or \"cpu\"\n",
    "    \"\"\"\n",
    "\n",
    "    # set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    batches = 0\n",
    "    for data in data_loader:\n",
    "\n",
    "        input = data.ger_sent.to(device)\n",
    "        target = data.eng_sent.to(device)\n",
    "\n",
    "        input = input.permute(1, 0)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # pass the input and target for model's forward method\n",
    "        output = model(input, target, english_vocab_size)\n",
    "\n",
    "        output = output.permute(1, 0, 2)\n",
    "\n",
    "        # print(output.shape)\n",
    "\n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "\n",
    "        target = target.permute(1, 0)\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # back-prop\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the gradient value if it exceeds 1 => called NORM clipping  (https://www.youtube.com/watch?v=_-CZr06R5CQ)\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # update the weight values\n",
    "        optimizer.step()\n",
    "\n",
    "        batches += 1.0\n",
    "        batch_loss += loss.item()\n",
    "\n",
    "    return batch_loss/batches\n",
    "\n",
    "\n",
    "def evaluate(data_loader, model, criterion, device):\n",
    "    \"\"\"\n",
    "    This function is used for returning loss\n",
    "\n",
    "    :param data_loader: this is the torch data loader\n",
    "    :param model: model (encoder - decoder model)\n",
    "    :param criterion: loss function\n",
    "    :param device: this can be \"cuda\" or \"cpu\"\n",
    "    \"\"\"\n",
    "\n",
    "    batch_loss = 0.0\n",
    "    batches = 0\n",
    "\n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for data in data_loader:\n",
    "\n",
    "            input = data.ger_sent.to(device)\n",
    "            target = data.eng_sent.to(device)\n",
    "\n",
    "            # pass the input and target for model's forward method\n",
    "            output = model(input, target, eng_vocab_size)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            batches += 1.0\n",
    "            batch_loss += loss.item()\n",
    "\n",
    "    return batch_loss/batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "common-interstate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:29.891309Z",
     "iopub.status.busy": "2021-06-23T08:10:29.890812Z",
     "iopub.status.idle": "2021-06-23T08:10:54.146772Z",
     "shell.execute_reply": "2021-06-23T08:10:54.146240Z",
     "shell.execute_reply.started": "2021-06-23T08:06:28.966741Z"
    },
    "papermill": {
     "duration": 24.269776,
     "end_time": "2021-06-23T08:10:54.146901",
     "exception": false,
     "start_time": "2021-06-23T08:10:29.877125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 12.0 MB 9.3 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.5)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.59.0)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('en_core_web_sm')\r\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\r\n",
      "/opt/conda/lib/python3.7/site-packages/en_core_web_sm -->\r\n",
      "/opt/conda/lib/python3.7/site-packages/spacy/data/en\r\n",
      "You can now load the model via spacy.load('en')\r\n",
      "Collecting de_core_news_sm==2.3.0\r\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 8.0 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from de_core_news_sm==2.3.0) (2.3.5)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.19.5)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.25.1)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.59.0)\r\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.5)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\r\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.4)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.2)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\r\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.7.4.3)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.0.0)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.26.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.12.5)\r\n",
      "Building wheels for collected packages: de-core-news-sm\r\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-py3-none-any.whl size=14907581 sha256=0ed231a8bdc9011dbcc99aa5e572e5ba6f3e81363759a233029854153022fb80\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n9eg6fjs/wheels/75/30/c3/ea1c6002eede7f49c8ab017ce62a2981a87b1cd39fab6e6a65\r\n",
      "Successfully built de-core-news-sm\r\n",
      "Installing collected packages: de-core-news-sm\r\n",
      "Successfully installed de-core-news-sm-2.3.0\r\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\r\n",
      "You can now load the model via spacy.load('de_core_news_sm')\r\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\r\n",
      "/opt/conda/lib/python3.7/site-packages/de_core_news_sm -->\r\n",
      "/opt/conda/lib/python3.7/site-packages/spacy/data/de\r\n",
      "You can now load the model via spacy.load('de')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emotional-reference",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:54.206187Z",
     "iopub.status.busy": "2021-06-23T08:10:54.205616Z",
     "iopub.status.idle": "2021-06-23T08:10:54.209579Z",
     "shell.execute_reply": "2021-06-23T08:10:54.209069Z",
     "shell.execute_reply.started": "2021-06-23T08:07:01.440185Z"
    },
    "papermill": {
     "duration": 0.037816,
     "end_time": "2021-06-23T08:10:54.209695",
     "exception": false,
     "start_time": "2021-06-23T08:10:54.171879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
    "    print('saving')\n",
    "    print()\n",
    "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
    "    torch.save(state, '/kaggle/working/checkpoint-NMT-BEST.pth')\n",
    "    torch.save(model.state_dict(),'/kaggle/working/checkpoint-NMT-BEST-SD.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recorded-database",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:10:54.270788Z",
     "iopub.status.busy": "2021-06-23T08:10:54.270084Z",
     "iopub.status.idle": "2021-06-23T08:11:02.200935Z",
     "shell.execute_reply": "2021-06-23T08:11:02.201302Z",
     "shell.execute_reply.started": "2021-06-23T08:07:08.757567Z"
    },
    "papermill": {
     "duration": 7.967418,
     "end_time": "2021-06-23T08:11:02.201455",
     "exception": false,
     "start_time": "2021-06-23T08:10:54.234037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Vocab Size : 5375\n",
      "English Vocab Size : 4556\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import spacy\n",
    "from torchtext.data.metrics import bleu_score\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "def tokenize_german(text):\n",
    "    \"\"\"\n",
    "    tokenizer for German language\n",
    "    \"\"\"\n",
    "    return [token.text for token in spacy_german.tokenizer(text)]\n",
    "\n",
    "def tokenize_english(text):\n",
    "    \"\"\"\n",
    "    tokenizer for English language\n",
    "    \"\"\"\n",
    "    return [token.text for token in spacy_english.tokenizer(text)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # tokenizers for German and English\n",
    "    spacy_german = spacy.load(\"de\")\n",
    "    spacy_english = spacy.load(\"en\")\n",
    "\n",
    "    # Field Object for German\n",
    "    german = Field(tokenize=tokenize_german,\n",
    "                    lower=True,\n",
    "                    init_token=\"<sos>\",\n",
    "                    eos_token=\"<eos>\"\n",
    "    )\n",
    "\n",
    "    # Field Object for English\n",
    "    english = Field(tokenize=tokenize_english,\n",
    "                    lower=True,\n",
    "                    init_token=\"<sos>\",\n",
    "                    eos_token=\"<eos>\"\n",
    "    )\n",
    "\n",
    "    # dataset object\n",
    "    dataset = TabularDataset(path=\"../input/german-to-english/dataset.csv\",\n",
    "                            format='csv',\n",
    "                            skip_header=True,\n",
    "                            fields=[('ger_sent', german), ('eng_sent', english)]\n",
    "    )\n",
    "\n",
    "    # 80% training\n",
    "    train_dataset, test_dataset = dataset.split(split_ratio=0.80)\n",
    "    train_dataset = dataset\n",
    "    \n",
    "    # BUILDING THE VOCAB\n",
    "    german.build_vocab(train_dataset, max_size=10000, min_freq=3)\n",
    "    english.build_vocab(train_dataset, max_size=10000, min_freq=3)\n",
    "\n",
    "    GERMAN_VOCAB = german.vocab\n",
    "    ENGLISH_VOCAB = english.vocab\n",
    "\n",
    "    print(f\"German Vocab Size : {len(GERMAN_VOCAB)}\")\n",
    "    print(f\"English Vocab Size : {len(ENGLISH_VOCAB)}\")\n",
    "\n",
    "    # set up the device to cuda\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    TRAIN_BATCH_SIZE = train_batch_size\n",
    "    TEST_BATCH_SIZE = test_batch_size\n",
    "\n",
    "    # Iterators\n",
    "    train_iterator, test_iterator = BucketIterator.splits(\n",
    "        (train_dataset, test_dataset),\n",
    "        batch_sizes=(TRAIN_BATCH_SIZE,TEST_BATCH_SIZE),\n",
    "        sort_within_batch = True,\n",
    "        sort_key=lambda x: len(x.ger_sent),\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # if we wanna explore the data in train and test iterators\n",
    "    # use this function\n",
    "#     testing_Iterators(train_iterator, test_iterator, GERMAN_VOCAB, ENGLISH_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "departmental-trial",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T08:11:02.260300Z",
     "iopub.status.busy": "2021-06-23T08:11:02.259563Z",
     "iopub.status.idle": "2021-06-23T11:05:13.021125Z",
     "shell.execute_reply": "2021-06-23T11:05:13.021591Z",
     "shell.execute_reply.started": "2021-06-23T08:08:04.831022Z"
    },
    "papermill": {
     "duration": 10450.796138,
     "end_time": "2021-06-23T11:05:13.021775",
     "exception": false,
     "start_time": "2021-06-23T08:11:02.225637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training started :)\n",
      "Seq2Seq(\n",
      "  (Encoder_LSTM): Encoder(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(5375, 300)\n",
      "    (rnn): LSTM(300, 1024, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  )\n",
      "  (Decoder_LSTM): Decoder(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(4556, 300)\n",
      "    (rnn): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "    (fc): Linear(in_features=1024, out_features=4556, bias=True)\n",
      "  )\n",
      ")\n",
      "['grabbing', 'costume', 'family', 'excited', 'rain', 'perform', 'rain', 'rain', 'carts', 'rain', 'carts', 'rain', 'paper', 'pond', 'walker', 'cigarette', 'project', 'project', 'maybe', 'utility', 'instructor', 'trotting', 'posing', 'rails', 'megaphone', 'parachute', 'parachute', 'chasing', 'clear', 'clear', 'blonds', 'pace', 'construction', 'suv', 'excited', 'excited', 'intense', 'streaks', 'shadows', 'shadows', 'dotted', 'pushing', 'pull', 'mittens', 'mittens', 'nintendo', 'sticker', 'sport', 'fallen', 'van']\n",
      "Epoch : 0 ; Epoch Loss : 5.071082813697949\n",
      "Testing Bleu Score : 0.03381622445777247\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'a', 'shirt', 'and', 'a', 'a', 'a', 'a', '.', '.', '<eos>']\n",
      "Epoch : 1 ; Epoch Loss : 4.4589335625631765\n",
      "Testing Bleu Score : 0.06999564825779478\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'and', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 2 ; Epoch Loss : 4.092260578222442\n",
      "Testing Bleu Score : 0.08155042801808185\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'white', 'shirt', 'is', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 3 ; Epoch Loss : 3.8275986219707288\n",
      "Testing Bleu Score : 0.1144509280373717\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 4 ; Epoch Loss : 3.6485651020418133\n",
      "Testing Bleu Score : 0.13090614204264617\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'white', 'shirt', 'is', 'sitting', 'on', 'a', 'bench', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 5 ; Epoch Loss : 3.4488465284046375\n",
      "Testing Bleu Score : 0.13224803058767343\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'white', 'shirt', 'standing', 'on', 'a', 'ladder', 'and', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 6 ; Epoch Loss : 3.3641650425760368\n",
      "Testing Bleu Score : 0.16740282712509078\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 7 ; Epoch Loss : 3.264748631862172\n",
      "Testing Bleu Score : 0.1552749861463731\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'rug', 'of', 'a', '.', '<eos>']\n",
      "Epoch : 8 ; Epoch Loss : 3.1538339372266804\n",
      "Testing Bleu Score : 0.15618710992507842\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'looking', 'at', 'a', 'newspaper', '.', '<eos>']\n",
      "Epoch : 9 ; Epoch Loss : 3.079397345844068\n",
      "Testing Bleu Score : 0.17831184938383163\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'in', 'a', '.', '.', '<eos>']\n",
      "Epoch : 10 ; Epoch Loss : 2.9688010215759277\n",
      "Testing Bleu Score : 0.16512695962391058\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'looking', 'at', 'a', '.', '.', '<eos>']\n",
      "Epoch : 11 ; Epoch Loss : 2.8764953906076\n",
      "Testing Bleu Score : 0.18895675033192452\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'in', 'a', 'middle', 'of', '<eos>']\n",
      "Epoch : 12 ; Epoch Loss : 2.8155494091803566\n",
      "Testing Bleu Score : 0.21729671419633367\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 13 ; Epoch Loss : 2.7374364053993894\n",
      "Testing Bleu Score : 0.19651611810647976\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'red', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'looking', 'at', '.', '<eos>']\n",
      "Epoch : 14 ; Epoch Loss : 2.6698409308466995\n",
      "Testing Bleu Score : 0.2020556132603663\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'looking', 'at', 'a', '.', '.', '<eos>']\n",
      "Epoch : 15 ; Epoch Loss : 2.605531891187032\n",
      "Testing Bleu Score : 0.24506791536812744\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'taking', 'a', 'picture', '.', '<eos>']\n",
      "Epoch : 16 ; Epoch Loss : 2.540453321055362\n",
      "Testing Bleu Score : 0.23309336846881906\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'looking', 'at', 'a', '.', '.', '<eos>']\n",
      "Epoch : 17 ; Epoch Loss : 2.487403486904345\n",
      "Testing Bleu Score : 0.24807382137296582\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'taking', 'a', 'picture', '.', '<eos>']\n",
      "Epoch : 18 ; Epoch Loss : 2.409131860523893\n",
      "Testing Bleu Score : 0.24324215082935277\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'taking', 'a', 'picture', '.', '<eos>']\n",
      "Epoch : 19 ; Epoch Loss : 2.384293194402728\n",
      "Testing Bleu Score : 0.2604244358944023\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'in', 'a', 'office', '.', '<eos>']\n",
      "Epoch : 20 ; Epoch Loss : 2.3458775585157827\n",
      "Testing Bleu Score : 0.2613591739930225\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'looking', 'at', 'a', '.', '<eos>']\n",
      "Epoch : 21 ; Epoch Loss : 2.2740382939054253\n",
      "Testing Bleu Score : 0.27961411887238424\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', '.', '<eos>']\n",
      "Epoch : 22 ; Epoch Loss : 2.2463641198057878\n",
      "Testing Bleu Score : 0.2775888233992725\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 23 ; Epoch Loss : 2.1667134322618185\n",
      "Testing Bleu Score : 0.2816335774258938\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'roof', '.', '<eos>']\n",
      "Epoch : 24 ; Epoch Loss : 2.1153991149182905\n",
      "Testing Bleu Score : 0.2986736955804735\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'cleaning', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 25 ; Epoch Loss : 2.0833506751478765\n",
      "Testing Bleu Score : 0.3386335180340779\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 26 ; Epoch Loss : 2.0619020273810937\n",
      "Testing Bleu Score : 0.33838530957446955\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 27 ; Epoch Loss : 2.008855429657719\n",
      "Testing Bleu Score : 0.3286028862322422\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'looking', 'at', 'a', '.', '<eos>']\n",
      "Epoch : 28 ; Epoch Loss : 1.9775569198424356\n",
      "Testing Bleu Score : 0.35752809959421034\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'cleaning', '.', '<eos>']\n",
      "Epoch : 29 ; Epoch Loss : 1.951860343155108\n",
      "Testing Bleu Score : 0.3196345854708422\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', '<eos>']\n",
      "Epoch : 30 ; Epoch Loss : 1.9395713084622432\n",
      "Testing Bleu Score : 0.33238378309842864\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'in', 'the', 'store', '.', '<eos>']\n",
      "Epoch : 31 ; Epoch Loss : 1.8805352867695324\n",
      "Testing Bleu Score : 0.3432695501771132\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 32 ; Epoch Loss : 1.8757418477744388\n",
      "Testing Bleu Score : 0.3533172210585038\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'roof', 'of', 'a', 'train', '.', '<eos>']\n",
      "Epoch : 33 ; Epoch Loss : 1.82984361313937\n",
      "Testing Bleu Score : 0.3646812718954556\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', '.', '<eos>']\n",
      "Epoch : 34 ; Epoch Loss : 1.825017669744659\n",
      "Testing Bleu Score : 0.3758738064363909\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 35 ; Epoch Loss : 1.7907090553066187\n",
      "Testing Bleu Score : 0.3817345072893056\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', '.', '<eos>']\n",
      "Epoch : 36 ; Epoch Loss : 1.7588793154348408\n",
      "Testing Bleu Score : 0.3919792203961507\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'scaffolding', 'looking', 'at', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 37 ; Epoch Loss : 1.7838954779139735\n",
      "Testing Bleu Score : 0.40289479098271486\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 38 ; Epoch Loss : 1.7095716930272287\n",
      "Testing Bleu Score : 0.3797957864865694\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'in', 'front', 'of', 'a', 'store', '.', '<eos>']\n",
      "Epoch : 39 ; Epoch Loss : 1.6828008105880337\n",
      "Testing Bleu Score : 0.42697129238283327\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 40 ; Epoch Loss : 1.6523251062945317\n",
      "Testing Bleu Score : 0.3989775803177453\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'podium', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 41 ; Epoch Loss : 1.645919050040998\n",
      "Testing Bleu Score : 0.4234274442398062\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'of', 'a', '.', '<eos>']\n",
      "Epoch : 42 ; Epoch Loss : 1.6360362203497636\n",
      "Testing Bleu Score : 0.42935429976596334\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 43 ; Epoch Loss : 1.622026032523105\n",
      "Testing Bleu Score : 0.4118711217428919\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 44 ; Epoch Loss : 1.5843483512861687\n",
      "Testing Bleu Score : 0.42815245052280565\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 45 ; Epoch Loss : 1.5754897249372382\n",
      "Testing Bleu Score : 0.4320653105553394\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 46 ; Epoch Loss : 1.5439778650016116\n",
      "Testing Bleu Score : 0.48119849642194185\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 47 ; Epoch Loss : 1.511600596862927\n",
      "Testing Bleu Score : 0.4388059138229761\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'in', 'a', 'store', '.', '<eos>']\n",
      "Epoch : 48 ; Epoch Loss : 1.5198644315987302\n",
      "Testing Bleu Score : 0.45265963138545273\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'on', 'a', 'ladder', 'cleaning', 'a', 'pole', '.', '<eos>']\n",
      "Epoch : 49 ; Epoch Loss : 1.485604088557394\n",
      "Testing Bleu Score : 0.4604589554827234\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 50 ; Epoch Loss : 1.465936381565897\n",
      "Testing Bleu Score : 0.5014893829652561\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'on', 'a', 'ladder', 'cleaning', 'a', 'a', '.', '<eos>']\n",
      "Epoch : 51 ; Epoch Loss : 1.4444075352267216\n",
      "Testing Bleu Score : 0.4464677057164526\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'on', 'a', 'ladder', 'cleaning', 'a', 'piece', 'of', 'food', '.', '<eos>']\n",
      "Epoch : 52 ; Epoch Loss : 1.441076958388613\n",
      "Testing Bleu Score : 0.4536932414808755\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 53 ; Epoch Loss : 1.435449222723643\n",
      "Testing Bleu Score : 0.4597515651658325\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'at', 'a', 'podium', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 54 ; Epoch Loss : 1.4307730187449539\n",
      "Testing Bleu Score : 0.5044455008304635\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 55 ; Epoch Loss : 1.4208301138459591\n",
      "Testing Bleu Score : 0.4652781509826378\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'stands', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 56 ; Epoch Loss : 1.4029974717842906\n",
      "Testing Bleu Score : 0.5063877962289125\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'podium', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 57 ; Epoch Loss : 1.3820324121860035\n",
      "Testing Bleu Score : 0.49597245423719505\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 58 ; Epoch Loss : 1.3639610357451857\n",
      "Testing Bleu Score : 0.5263930559158325\n",
      "saving\n",
      "\n",
      "['man', 'in', 'a', 'blue', 'shirt', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'wall', '.', '<eos>']\n",
      "Epoch : 59 ; Epoch Loss : 1.3459140511981227\n",
      "Testing Bleu Score : 0.5299666682268347\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 60 ; Epoch Loss : 1.3513797464077932\n",
      "Testing Bleu Score : 0.5312776293936861\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 61 ; Epoch Loss : 1.316246161335393\n",
      "Testing Bleu Score : 0.5220172899298744\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'painting', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 62 ; Epoch Loss : 1.33827298043067\n",
      "Testing Bleu Score : 0.5230228790392422\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 63 ; Epoch Loss : 1.2942200371047907\n",
      "Testing Bleu Score : 0.5428564548492432\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 64 ; Epoch Loss : 1.2984607204010612\n",
      "Testing Bleu Score : 0.5428158165801188\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'podium', 'cleaning', 'a', 'newspaper', '.', '<eos>']\n",
      "Epoch : 65 ; Epoch Loss : 1.2751284429901524\n",
      "Testing Bleu Score : 0.5478894506342463\n",
      "saving\n",
      "\n",
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n",
      "Epoch : 66 ; Epoch Loss : 1.2831515377027947\n",
      "Testing Bleu Score : 0.5158459370195131\n",
      "Early Stopping...\n"
     ]
    }
   ],
   "source": [
    "# Let's create the model\n",
    "# ENCODER : \n",
    "input_size_encoder = len(GERMAN_VOCAB)  # vocab size\n",
    "encoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "encoder_dropout = float(0.5)\n",
    "\n",
    "encoder_lstm = Encoder(input_size_encoder, encoder_embedding_size, \n",
    "                        hidden_size, num_layers, encoder_dropout).to(device)\n",
    "\n",
    "# DECODER : \n",
    "input_size_decoder = len(ENGLISH_VOCAB)\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "decoder_dropout = float(0.5)\n",
    "output_size = len(ENGLISH_VOCAB)\n",
    "\n",
    "decoder_lstm = Decoder(input_size_decoder, decoder_embedding_size, hidden_size, \n",
    "                        num_layers, decoder_dropout, output_size).to(device)\n",
    "\n",
    "\n",
    "my_model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
    "\n",
    "# Let's train the model\n",
    "print(\"Model Training started :)\")\n",
    "\n",
    "EPOCHS = epochs\n",
    "learning_rate = learning_rate\n",
    "\n",
    "epoch_loss = 0.0\n",
    "best_loss = 10**7\n",
    "best_epoch = -1\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=learning_rate)\n",
    "pad_idx = ENGLISH_VOCAB.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "early_stopping_counter = 0\n",
    "print(my_model, end=\"\\n\")\n",
    "\n",
    "# for checking the model at every step\n",
    "sample_sentence = \"ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster\"\n",
    "\n",
    "train_losses = []\n",
    "test_bleu_scores = []\n",
    "print(translate_sentence(my_model, sample_sentence, german, english, device))\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    epoch_loss = train(train_iterator, my_model, optimizer, criterion, len(ENGLISH_VOCAB), device)\n",
    "\n",
    "    # Append the training loss\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f\"Epoch : {epoch} ; Epoch Loss : {epoch_loss}\")\n",
    "\n",
    "    # print the bleu bleu score for testing # update to 1:100\n",
    "    print(f\"Testing Bleu Score : {bleu(test_dataset[1:100], my_model, german, english, device)}\")\n",
    "\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_epoch = epoch\n",
    "        checkpoint_and_save(my_model, best_loss, epoch, optimizer, epoch_loss)\n",
    "\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter > 5:\n",
    "        print(\"Early Stopping...\")\n",
    "        break\n",
    "\n",
    "    print(translate_sentence(my_model, sample_sentence, german, english, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "relative-litigation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T11:05:13.191172Z",
     "iopub.status.busy": "2021-06-23T11:05:13.190260Z",
     "iopub.status.idle": "2021-06-23T11:05:13.192935Z",
     "shell.execute_reply": "2021-06-23T11:05:13.192529Z",
     "shell.execute_reply.started": "2021-06-23T08:08:50.730618Z"
    },
    "papermill": {
     "duration": 0.089143,
     "end_time": "2021-06-23T11:05:13.193047",
     "exception": false,
     "start_time": "2021-06-23T11:05:13.103904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tropical-negative",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T11:05:13.360864Z",
     "iopub.status.busy": "2021-06-23T11:05:13.359757Z",
     "iopub.status.idle": "2021-06-23T11:05:13.728978Z",
     "shell.execute_reply": "2021-06-23T11:05:13.729410Z",
     "shell.execute_reply.started": "2021-06-23T08:08:51.203300Z"
    },
    "papermill": {
     "duration": 0.454887,
     "end_time": "2021-06-23T11:05:13.729578",
     "exception": false,
     "start_time": "2021-06-23T11:05:13.274691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk = torch.load(\"./checkpoint-NMT-BEST.pth\")\n",
    "mm = chk['model']\n",
    "\n",
    "sd = torch.load(\"./checkpoint-NMT-BEST-SD.pth\")\n",
    "mm.load_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blank-oklahoma",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-23T11:05:13.895257Z",
     "iopub.status.busy": "2021-06-23T11:05:13.894457Z",
     "iopub.status.idle": "2021-06-23T11:05:15.159275Z",
     "shell.execute_reply": "2021-06-23T11:05:15.158801Z",
     "shell.execute_reply.started": "2021-06-23T08:08:52.994478Z"
    },
    "papermill": {
     "duration": 1.349244,
     "end_time": "2021-06-23T11:05:15.159420",
     "exception": false,
     "start_time": "2021-06-23T11:05:13.810176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'man', 'in', 'a', 'blue', 'shirt', 'is', 'standing', 'on', 'a', 'ladder', 'cleaning', 'a', 'window', '.', '<eos>']\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(mm, sample_sentence, german, english, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-mechanics",
   "metadata": {
    "papermill": {
     "duration": 0.076787,
     "end_time": "2021-06-23T11:05:15.316045",
     "exception": false,
     "start_time": "2021-06-23T11:05:15.239258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10504.697231,
   "end_time": "2021-06-23T11:05:17.873356",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-23T08:10:13.176125",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
