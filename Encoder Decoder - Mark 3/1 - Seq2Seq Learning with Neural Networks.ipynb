{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "917cdc91",
   "metadata": {
    "id": "HY-X5J9ux9OC",
    "papermill": {
     "duration": 0.024812,
     "end_time": "2021-09-28T21:52:03.841438",
     "exception": false,
     "start_time": "2021-09-28T21:52:03.816626",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparaing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115b38fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:03.895316Z",
     "iopub.status.busy": "2021-09-28T21:52:03.893748Z",
     "iopub.status.idle": "2021-09-28T21:52:10.980840Z",
     "shell.execute_reply": "2021-09-28T21:52:10.979668Z",
     "shell.execute_reply.started": "2021-09-28T21:47:13.974243Z"
    },
    "id": "o0SSw_4oxItW",
    "papermill": {
     "duration": 7.114542,
     "end_time": "2021-09-28T21:52:10.981000",
     "exception": false,
     "start_time": "2021-09-28T21:52:03.866458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfec8533",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:11.038088Z",
     "iopub.status.busy": "2021-09-28T21:52:11.037236Z",
     "iopub.status.idle": "2021-09-28T21:52:11.042558Z",
     "shell.execute_reply": "2021-09-28T21:52:11.041943Z",
     "shell.execute_reply.started": "2021-09-28T21:43:19.879335Z"
    },
    "id": "uUNMBaLwyQWx",
    "papermill": {
     "duration": 0.035793,
     "end_time": "2021-09-28T21:52:11.042688",
     "exception": false,
     "start_time": "2021-09-28T21:52:11.006895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60138253",
   "metadata": {
    "id": "fnteO7uey9B6",
    "papermill": {
     "duration": 0.024737,
     "end_time": "2021-09-28T21:52:11.094824",
     "exception": false,
     "start_time": "2021-09-28T21:52:11.070087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2caa15a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:11.147015Z",
     "iopub.status.busy": "2021-09-28T21:52:11.146225Z",
     "iopub.status.idle": "2021-09-28T21:52:30.689948Z",
     "shell.execute_reply": "2021-09-28T21:52:30.689533Z",
     "shell.execute_reply.started": "2021-09-28T21:45:46.501734Z"
    },
    "id": "2JFiA0OZy8ch",
    "outputId": "9781055a-d85d-4765-d600-0936a2cec72b",
    "papermill": {
     "duration": 19.571587,
     "end_time": "2021-09-28T21:52:30.690101",
     "exception": false,
     "start_time": "2021-09-28T21:52:11.118514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.62.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "Collecting de_core_news_sm==2.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from de_core_news_sm==2.3.0) (2.3.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (57.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.25.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.62.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2021.5.30)\n",
      "Building wheels for collected packages: de-core-news-sm\n",
      "  Building wheel for de-core-news-sm (setup.py): started\n",
      "  Building wheel for de-core-news-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-py3-none-any.whl size=14907580 sha256=2d72db2b648098d7e6be189b27b874b92ab8cea921f03cba3289632f08bba58a\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/30/c3/ea1c6002eede7f49c8ab017ce62a2981a87b1cd39fab6e6a65\n",
      "Successfully built de-core-news-sm\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-2.3.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/62822737/oserror-e050-cant-find-model-de-it-doesnt-seem-to-be-a-shortcut-link-a\n",
    "\n",
    "import spacy.cli \n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "spacy.cli.download(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea7a389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:30.748516Z",
     "iopub.status.busy": "2021-09-28T21:52:30.747748Z",
     "iopub.status.idle": "2021-09-28T21:52:33.092754Z",
     "shell.execute_reply": "2021-09-28T21:52:33.092245Z",
     "shell.execute_reply.started": "2021-09-28T21:46:08.812787Z"
    },
    "id": "ql84cfHuyeHq",
    "outputId": "43f8f307-21c2-4a2e-aba2-ad4bf0c47952",
    "papermill": {
     "duration": 2.375337,
     "end_time": "2021-09-28T21:52:33.092875",
     "exception": false,
     "start_time": "2021-09-28T21:52:30.717538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating tokenizers\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f723b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:33.152576Z",
     "iopub.status.busy": "2021-09-28T21:52:33.151778Z",
     "iopub.status.idle": "2021-09-28T21:52:33.153810Z",
     "shell.execute_reply": "2021-09-28T21:52:33.154239Z",
     "shell.execute_reply.started": "2021-09-28T21:46:39.208069Z"
    },
    "id": "rBh0ogVTy55j",
    "papermill": {
     "duration": 0.034276,
     "end_time": "2021-09-28T21:52:33.154367",
     "exception": false,
     "start_time": "2021-09-28T21:52:33.120091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenizer functions for German and English\n",
    "\n",
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings (tokens)\n",
    "    and reverses it\n",
    "    \n",
    "    :param text: the german sentence\n",
    "    \"\"\"\n",
    "\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings (tokens)\n",
    "\n",
    "    :param text: the english sentence\n",
    "    \"\"\"\n",
    "\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70abd14b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:33.212744Z",
     "iopub.status.busy": "2021-09-28T21:52:33.211927Z",
     "iopub.status.idle": "2021-09-28T21:52:33.213885Z",
     "shell.execute_reply": "2021-09-28T21:52:33.214349Z",
     "shell.execute_reply.started": "2021-09-28T21:47:17.718324Z"
    },
    "id": "vBz8Nc4P0_UA",
    "papermill": {
     "duration": 0.033,
     "end_time": "2021-09-28T21:52:33.214472",
     "exception": false,
     "start_time": "2021-09-28T21:52:33.181472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Source is German and Target is English\n",
    "\n",
    "SRC = Field(tokenize = tokenize_de,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en,\n",
    "            init_token = '<sos>',\n",
    "            eos_token = '<eos>',\n",
    "            lower = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c34aef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:33.272412Z",
     "iopub.status.busy": "2021-09-28T21:52:33.271642Z",
     "iopub.status.idle": "2021-09-28T21:52:45.096773Z",
     "shell.execute_reply": "2021-09-28T21:52:45.096285Z",
     "shell.execute_reply.started": "2021-09-28T21:47:18.960211Z"
    },
    "id": "1gDvbENL1cId",
    "outputId": "e0bf7722-e764-4a94-b7be-3e15767d98d0",
    "papermill": {
     "duration": 11.855786,
     "end_time": "2021-09-28T21:52:45.096901",
     "exception": false,
     "start_time": "2021-09-28T21:52:33.241115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.21M/1.21M [00:02<00:00, 547kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 46.3k/46.3k [00:00<00:00, 167kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66.2k/66.2k [00:00<00:00, 160kB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download and load the train, valid and test data\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'),\n",
    "    fields = (SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87449deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:45.183201Z",
     "iopub.status.busy": "2021-09-28T21:52:45.182577Z",
     "iopub.status.idle": "2021-09-28T21:52:45.185211Z",
     "shell.execute_reply": "2021-09-28T21:52:45.185621Z",
     "shell.execute_reply.started": "2021-09-28T21:47:25.628960Z"
    },
    "id": "t_v8D_871pfZ",
    "outputId": "68ea3b23-c9c0-492a-9182-75fc7d7ea636",
    "papermill": {
     "duration": 0.053612,
     "end_time": "2021-09-28T21:52:45.185760",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.132148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 29000\n",
      "Number of validation examples: 1014\n",
      "Number of testing examples: 1000\n",
      "{'src': ['.', 'bÃ¼sche', 'vieler', 'nÃ¤he', 'der', 'in', 'freien', 'im', 'sind', 'mÃ¤nner', 'weiÃŸe', 'junge', 'zwei'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"
     ]
    }
   ],
   "source": [
    "# Verifying\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a089f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:45.268709Z",
     "iopub.status.busy": "2021-09-28T21:52:45.258838Z",
     "iopub.status.idle": "2021-09-28T21:52:45.539644Z",
     "shell.execute_reply": "2021-09-28T21:52:45.539150Z",
     "shell.execute_reply.started": "2021-09-28T21:47:26.832447Z"
    },
    "id": "n9jVhzVe1ugy",
    "papermill": {
     "duration": 0.318749,
     "end_time": "2021-09-28T21:52:45.539760",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.221011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# building vocabulary\n",
    "# min_freq => min threshold to include the word in the vocab\n",
    "\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c3d7669",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:45.614810Z",
     "iopub.status.busy": "2021-09-28T21:52:45.614298Z",
     "iopub.status.idle": "2021-09-28T21:52:45.620258Z",
     "shell.execute_reply": "2021-09-28T21:52:45.619640Z",
     "shell.execute_reply.started": "2021-09-28T21:47:28.424117Z"
    },
    "id": "QzJ-Nte710hb",
    "outputId": "19cf9f52-8bfc-4787-a731-3f69a0b84565",
    "papermill": {
     "duration": 0.045101,
     "end_time": "2021-09-28T21:52:45.620396",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.575295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in source (de) vocabulary: 7854\n",
      "Unique tokens in target (en) vocabulary: 5893\n"
     ]
    }
   ],
   "source": [
    "# Unique tokens\n",
    "print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n",
    "print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ec9bf",
   "metadata": {
    "id": "PpElvdFt22Nu",
    "papermill": {
     "duration": 0.034728,
     "end_time": "2021-09-28T21:52:45.690583",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.655855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8715585c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:45.816540Z",
     "iopub.status.busy": "2021-09-28T21:52:45.815760Z",
     "iopub.status.idle": "2021-09-28T21:52:45.818411Z",
     "shell.execute_reply": "2021-09-28T21:52:45.817733Z",
     "shell.execute_reply.started": "2021-09-28T21:47:30.945990Z"
    },
    "id": "KZFFszlg2Rql",
    "papermill": {
     "duration": 0.092904,
     "end_time": "2021-09-28T21:52:45.818527",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.725623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d032a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:45.896484Z",
     "iopub.status.busy": "2021-09-28T21:52:45.894880Z",
     "iopub.status.idle": "2021-09-28T21:52:45.898901Z",
     "shell.execute_reply": "2021-09-28T21:52:45.898516Z",
     "shell.execute_reply.started": "2021-09-28T21:47:33.126887Z"
    },
    "id": "zkN1hYbl2uL3",
    "papermill": {
     "duration": 0.044191,
     "end_time": "2021-09-28T21:52:45.899006",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.854815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e7387",
   "metadata": {
    "id": "X90iPbVJ3FWd",
    "papermill": {
     "duration": 0.035156,
     "end_time": "2021-09-28T21:52:45.969744",
     "exception": false,
     "start_time": "2021-09-28T21:52:45.934588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c9224a",
   "metadata": {
    "id": "d0zJVg2pLnDN",
    "papermill": {
     "duration": 0.035567,
     "end_time": "2021-09-28T21:52:46.041286",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.005719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5704f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:46.121316Z",
     "iopub.status.busy": "2021-09-28T21:52:46.120467Z",
     "iopub.status.idle": "2021-09-28T21:52:46.122973Z",
     "shell.execute_reply": "2021-09-28T21:52:46.122532Z",
     "shell.execute_reply.started": "2021-09-28T21:47:35.511767Z"
    },
    "id": "x3ih4nhn3ERA",
    "papermill": {
     "duration": 0.046208,
     "end_time": "2021-09-28T21:52:46.123100",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.076892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        :param input_dim: It is the size/dimensionality of the one-hot vectors that will be input to the encoder. \n",
    "                        This is equal to the input (source) vocabulary size.\n",
    "        :param emb_dim: It is the dimensionality of the embedding layer. \n",
    "                        This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "        :param hid_dim: It is the dimensionality of the hidden and cell states\n",
    "        :param n_layers: It is the number of layers in the RNN.\n",
    "        :param dropout: It is the amount of dropout to use. \n",
    "                        This is a regularization parameter to prevent overfitting.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "\n",
    "        # src.shape => (src_len, batch_size)\n",
    "\n",
    "        # example, src will be like:\n",
    "\n",
    "            # | I ,     Good,       How,    ... |\n",
    "            # | have,   morning,    are,    ... |\n",
    "            # | a,      <eos>,      you,    ... |\n",
    "            # | dog,    <pad>,      <eos>,  ... |\n",
    "            # | <eos>,  <pad>,      <pad>,  ... |\n",
    "\n",
    "            # In this number of rows = src_len or max_len\n",
    "            # and number of columns = batch_size\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded.shape => (src_len, batch_size, emb_dim)\n",
    "\n",
    "        outputs, (hidden, cell) = self.rnn(embedded) # by default, batch_first = False\n",
    "\n",
    "        # n_direction = 1 in this case as we are not using bi-directional rnn\n",
    "        # outputs.shape => (src_len, batch_size, hid_dim * n_direction)\n",
    "\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        # cell.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "\n",
    "        # Refer Notes:\n",
    "        # hidden, cell are forwarded to next time steps\n",
    "        # In this case, they are the final hidden, cell for the \n",
    "        # final time step/ layer\n",
    "        # n_directions = 2 if we use bi-directional LSTMs\n",
    "\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe431574",
   "metadata": {
    "id": "VaJA_6P__eEQ",
    "papermill": {
     "duration": 0.035639,
     "end_time": "2021-09-28T21:52:46.194333",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.158694",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b77e6358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:46.274126Z",
     "iopub.status.busy": "2021-09-28T21:52:46.273350Z",
     "iopub.status.idle": "2021-09-28T21:52:46.275263Z",
     "shell.execute_reply": "2021-09-28T21:52:46.275719Z",
     "shell.execute_reply.started": "2021-09-28T21:47:38.363739Z"
    },
    "id": "DeVlWrO2_dHR",
    "papermill": {
     "duration": 0.04623,
     "end_time": "2021-09-28T21:52:46.275842",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.229612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        \"\"\"\n",
    "        :param output_dim: It is the size/dimensionality of the one-hot vectors that will be input to the decoder. \n",
    "                        This is equal to the output (target) vocabulary size.\n",
    "                        It also used to output the word in the Linear layer.\n",
    "        :param emb_dim: It is the dimensionality of the embedding layer. \n",
    "                        This layer converts the one-hot vectors into dense vectors with emb_dim dimensions.\n",
    "        :param hid_dim: It is the dimensionality of the hidden and cell states\n",
    "        :param n_layers: It is the number of layers in the RNN.\n",
    "        :param dropout: It is the amount of dropout to use. \n",
    "                        This is a regularization parameter to prevent overfitting.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "\n",
    "        # input.shape => (batch_size)\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        # cell.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "\n",
    "        # n_directions in the decoder will both always be 1, therefore:\n",
    "        # hidden.shape => (n_layers, batch_size, hid_dim)\n",
    "        # cell.shape => (n_layers, batch_size, hid_dim)\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "        # input.shape => (1, batch_size)\n",
    "        # NOTE: the src_len for the input is going to be as we will give just\n",
    "        # the 1st word. Also, we will get just the next word (prediction).\n",
    "        # Hence, output seq_len will also be 1.\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded.shape => (1, batch_size, emb_dim)\n",
    "\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell)) # by default, batch_first = False\n",
    "\n",
    "        # output.shape => (seq_len, batch_size, hid_dim * n_directions)\n",
    "\n",
    "        # hidden.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "        # cell.shape => (n_layers * n_directions, batch_size, hid_dim)\n",
    "\n",
    "        # seq_len and n_directions will always be 1 in the decoder, therefore:\n",
    "\n",
    "        # output.shape => (1, batch_size, hid_dim)\n",
    "        # hidden.shape => (n_layers, batch_size, hid_dim)\n",
    "        # cell.shape => (n_layers, batch_size, hid_dim)\n",
    "\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "\n",
    "        # prediction.shape => (batch_size, output_dim)\n",
    "\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bc83ce",
   "metadata": {
    "id": "6EWmNPAiKfoH",
    "papermill": {
     "duration": 0.034918,
     "end_time": "2021-09-28T21:52:46.346406",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.311488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Seq2Seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b2efe57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:46.426394Z",
     "iopub.status.busy": "2021-09-28T21:52:46.425672Z",
     "iopub.status.idle": "2021-09-28T21:52:46.428135Z",
     "shell.execute_reply": "2021-09-28T21:52:46.427738Z",
     "shell.execute_reply.started": "2021-09-28T21:47:40.052575Z"
    },
    "id": "dTzVq9ifEGwZ",
    "papermill": {
     "duration": 0.046671,
     "end_time": "2021-09-28T21:52:46.428247",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.381576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal numebr of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "\n",
    "        \"\"\"\n",
    "        :param src: the source sentence sequence\n",
    "                    src.shape => (src_len, batch_size)\n",
    "        :param trg: the target sentence sequence\n",
    "                    trg.shape => (trg_len, batch_size)\n",
    "        :param teacher_forcing_ratio: the ratio, used for training. It tells \n",
    "                    by how much probability, we should use the decoded token or\n",
    "                    the original token for training\n",
    "                    e.g. if teacher_forcing_ratio is 0.75, \n",
    "                    we use ground-truth inputs 75% of the time.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # last hidden state of the encoder is used as the initial \n",
    "        # hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            # insert input token embedding, previous hidden and previous\n",
    "            # cell states, and\n",
    "            # recieve output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "\n",
    "            # place the predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "\n",
    "            # decide if we are going to use tracher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # get the highest predicted token from predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # else, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "\n",
    "        return outputs # outputs.shape => (trg_len, batch_size, output_dim)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac99ad5",
   "metadata": {
    "id": "H4X7DzWyPLsx",
    "papermill": {
     "duration": 0.034847,
     "end_time": "2021-09-28T21:52:46.498047",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.463200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Seq2Seq Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f199bbc",
   "metadata": {
    "id": "KaBCxwdWQhAT",
    "papermill": {
     "duration": 0.034889,
     "end_time": "2021-09-28T21:52:46.568216",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.533327",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae09e6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:46.643858Z",
     "iopub.status.busy": "2021-09-28T21:52:46.643255Z",
     "iopub.status.idle": "2021-09-28T21:52:52.396605Z",
     "shell.execute_reply": "2021-09-28T21:52:52.396107Z",
     "shell.execute_reply.started": "2021-09-28T21:47:42.840600Z"
    },
    "id": "zkicKXBzPKFW",
    "papermill": {
     "duration": 5.793431,
     "end_time": "2021-09-28T21:52:52.396751",
     "exception": false,
     "start_time": "2021-09-28T21:52:46.603320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b711aa",
   "metadata": {
    "id": "W8hEKJlcQVmC",
    "papermill": {
     "duration": 0.037746,
     "end_time": "2021-09-28T21:52:52.471655",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.433909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Initializing weights of the model.\n",
    "* In the paper they state they initialize all weights from a uniform distribution between -0.08 and +0.08, i.e. $\\mathcal{U}(-0.08, 0.08)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86397568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:52.548342Z",
     "iopub.status.busy": "2021-09-28T21:52:52.547421Z",
     "iopub.status.idle": "2021-09-28T21:52:52.556945Z",
     "shell.execute_reply": "2021-09-28T21:52:52.557377Z",
     "shell.execute_reply.started": "2021-09-28T21:47:52.719811Z"
    },
    "id": "SA9j822RP8Tp",
    "outputId": "f68dfaff-c6cf-44de-ae12-189a8a3520f4",
    "papermill": {
     "duration": 0.05022,
     "end_time": "2021-09-28T21:52:52.557507",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.507287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7854, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "        initializes the weights of the model.\n",
    "    \"\"\"\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dad4932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:52.634327Z",
     "iopub.status.busy": "2021-09-28T21:52:52.633675Z",
     "iopub.status.idle": "2021-09-28T21:52:52.637322Z",
     "shell.execute_reply": "2021-09-28T21:52:52.637700Z",
     "shell.execute_reply.started": "2021-09-28T21:47:54.718938Z"
    },
    "id": "mr8iU7mJQuB0",
    "outputId": "9fb8fcb7-3ed3-4db3-c035-a67fbb4a8279",
    "papermill": {
     "duration": 0.044532,
     "end_time": "2021-09-28T21:52:52.637828",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.593296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,898,757 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "        calculates the number of trainable parameters.\n",
    "    \"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "228c43ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:52.714119Z",
     "iopub.status.busy": "2021-09-28T21:52:52.713335Z",
     "iopub.status.idle": "2021-09-28T21:52:52.716049Z",
     "shell.execute_reply": "2021-09-28T21:52:52.715601Z",
     "shell.execute_reply.started": "2021-09-28T21:47:56.516172Z"
    },
    "id": "Uw43O8KuRGT3",
    "papermill": {
     "duration": 0.042359,
     "end_time": "2021-09-28T21:52:52.716156",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.673797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the optimizer\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10c881a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:52.792673Z",
     "iopub.status.busy": "2021-09-28T21:52:52.792160Z",
     "iopub.status.idle": "2021-09-28T21:52:52.795764Z",
     "shell.execute_reply": "2021-09-28T21:52:52.795275Z",
     "shell.execute_reply.started": "2021-09-28T21:47:58.425666Z"
    },
    "id": "SalbfhxGROE9",
    "papermill": {
     "duration": 0.043548,
     "end_time": "2021-09-28T21:52:52.795876",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.752328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "# NOTE: Our loss function calculates the average loss per token, \n",
    "# however by passing the index of the <pad> token as the ignore_index argument \n",
    "# we ignore the loss whenever the target token is a padding token.\n",
    "\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789f28a0",
   "metadata": {
    "id": "F233sXCKR_HR",
    "papermill": {
     "duration": 0.035875,
     "end_time": "2021-09-28T21:52:52.867947",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.832072",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9fee38f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:52.949089Z",
     "iopub.status.busy": "2021-09-28T21:52:52.947406Z",
     "iopub.status.idle": "2021-09-28T21:52:52.949752Z",
     "shell.execute_reply": "2021-09-28T21:52:52.950166Z",
     "shell.execute_reply.started": "2021-09-28T21:48:00.692691Z"
    },
    "id": "wIFIydTORxaR",
    "papermill": {
     "duration": 0.045927,
     "end_time": "2021-09-28T21:52:52.950285",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.904358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # trg.shape => (trg_len, batch_size)\n",
    "        # output.shape => (trg_len, batch_size, output_dim)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # ignoring the 1st token\n",
    "        output = output[1:].view(-1, output_dim) # in this case, it's 0\n",
    "        trg = trg[1:].view(-1) # in this case it's <sos>\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e731251",
   "metadata": {
    "id": "w179UhlgS-a6",
    "papermill": {
     "duration": 0.036571,
     "end_time": "2021-09-28T21:52:53.023441",
     "exception": false,
     "start_time": "2021-09-28T21:52:52.986870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f8e3402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:53.101843Z",
     "iopub.status.busy": "2021-09-28T21:52:53.101194Z",
     "iopub.status.idle": "2021-09-28T21:52:53.103532Z",
     "shell.execute_reply": "2021-09-28T21:52:53.103990Z",
     "shell.execute_reply.started": "2021-09-28T21:48:02.603183Z"
    },
    "id": "E3zUvkbDS7qT",
    "papermill": {
     "duration": 0.044446,
     "end_time": "2021-09-28T21:52:53.104123",
     "exception": false,
     "start_time": "2021-09-28T21:52:53.059677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) # turn off teacher forcing\n",
    "\n",
    "            # trg.shape => (trg_len, batch_size)\n",
    "            # output.shape => (trg_len, batch_size, output_dim)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "\n",
    "            # ignoring the 1st token\n",
    "            output = output[1:].view(-1, output_dim) # in this case, it's 0\n",
    "            trg = trg[1:].view(-1) # in this case it's <sos>\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f65b696c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:53.180459Z",
     "iopub.status.busy": "2021-09-28T21:52:53.179830Z",
     "iopub.status.idle": "2021-09-28T21:52:53.181940Z",
     "shell.execute_reply": "2021-09-28T21:52:53.182354Z",
     "shell.execute_reply.started": "2021-09-28T21:48:04.213254Z"
    },
    "id": "dFEDSwdhTdGV",
    "papermill": {
     "duration": 0.042321,
     "end_time": "2021-09-28T21:52:53.182464",
     "exception": false,
     "start_time": "2021-09-28T21:52:53.140143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f033bfb",
   "metadata": {
    "id": "jSMX9KJ1TlrI",
    "papermill": {
     "duration": 0.035358,
     "end_time": "2021-09-28T21:52:53.253673",
     "exception": false,
     "start_time": "2021-09-28T21:52:53.218315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e045d583",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:52:53.383525Z",
     "iopub.status.busy": "2021-09-28T21:52:53.367960Z",
     "iopub.status.idle": "2021-09-28T21:59:13.095575Z",
     "shell.execute_reply": "2021-09-28T21:59:13.096017Z",
     "shell.execute_reply.started": "2021-09-28T21:49:06.440154Z"
    },
    "id": "scjaMch3TfP5",
    "papermill": {
     "duration": 379.806491,
     "end_time": "2021-09-28T21:59:13.096208",
     "exception": false,
     "start_time": "2021-09-28T21:52:53.289717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 38s\n",
      "\tTrain Loss: 5.179 | Train PPL: 177.458\n",
      "\t Val. Loss: 5.049 |  Val. PPL: 155.855\n",
      "Epoch: 02 | Time: 0m 38s\n",
      "\tTrain Loss: 4.663 | Train PPL: 105.972\n",
      "\t Val. Loss: 5.208 |  Val. PPL: 182.655\n",
      "Epoch: 03 | Time: 0m 37s\n",
      "\tTrain Loss: 4.511 | Train PPL:  90.976\n",
      "\t Val. Loss: 5.270 |  Val. PPL: 194.484\n",
      "Epoch: 04 | Time: 0m 38s\n",
      "\tTrain Loss: 4.395 | Train PPL:  81.021\n",
      "\t Val. Loss: 5.275 |  Val. PPL: 195.375\n",
      "Epoch: 05 | Time: 0m 37s\n",
      "\tTrain Loss: 4.289 | Train PPL:  72.859\n",
      "\t Val. Loss: 5.076 |  Val. PPL: 160.159\n",
      "Epoch: 06 | Time: 0m 38s\n",
      "\tTrain Loss: 4.246 | Train PPL:  69.820\n",
      "\t Val. Loss: 5.038 |  Val. PPL: 154.220\n",
      "Epoch: 07 | Time: 0m 37s\n",
      "\tTrain Loss: 4.204 | Train PPL:  66.972\n",
      "\t Val. Loss: 5.094 |  Val. PPL: 162.979\n",
      "Epoch: 08 | Time: 0m 37s\n",
      "\tTrain Loss: 4.157 | Train PPL:  63.908\n",
      "\t Val. Loss: 4.973 |  Val. PPL: 144.426\n",
      "Epoch: 09 | Time: 0m 37s\n",
      "\tTrain Loss: 4.076 | Train PPL:  58.897\n",
      "\t Val. Loss: 5.064 |  Val. PPL: 158.215\n",
      "Epoch: 10 | Time: 0m 37s\n",
      "\tTrain Loss: 4.098 | Train PPL:  60.210\n",
      "\t Val. Loss: 4.909 |  Val. PPL: 135.546\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ae7d4",
   "metadata": {
    "id": "7MiNMd4_UM5q",
    "papermill": {
     "duration": 0.038046,
     "end_time": "2021-09-28T21:59:13.174349",
     "exception": false,
     "start_time": "2021-09-28T21:59:13.136303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1710746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-28T21:59:13.256956Z",
     "iopub.status.busy": "2021-09-28T21:59:13.255950Z",
     "iopub.status.idle": "2021-09-28T21:59:13.741046Z",
     "shell.execute_reply": "2021-09-28T21:59:13.741435Z",
     "shell.execute_reply.started": "2021-09-28T21:50:18.669390Z"
    },
    "id": "L6wSeNEFULxo",
    "papermill": {
     "duration": 0.528313,
     "end_time": "2021-09-28T21:59:13.741595",
     "exception": false,
     "start_time": "2021-09-28T21:59:13.213282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.935 | Test PPL: 139.122 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa23176",
   "metadata": {
    "papermill": {
     "duration": 0.039984,
     "end_time": "2021-09-28T21:59:13.820842",
     "exception": false,
     "start_time": "2021-09-28T21:59:13.780858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 438.773985,
   "end_time": "2021-09-28T21:59:16.126972",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-28T21:51:57.352987",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
